{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zTAIwvb1sAz"
   },
   "source": [
    "#Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gPLTXtj1lSU",
    "outputId": "b032ab09-4bf5-43d0-c06b-2e34f972deb4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: python-bioformats in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: boto3 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from python-bioformats) (1.20.24)\n",
      "Requirement already satisfied: future in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from python-bioformats) (0.18.2)\n",
      "Requirement already satisfied: javabridge>=1.0 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from python-bioformats) (1.0.16)\n",
      "Requirement already satisfied: numpy in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from javabridge>=1.0->python-bioformats) (1.20.1)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.24 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from boto3->python-bioformats) (1.23.24)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from boto3->python-bioformats) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from boto3->python-bioformats) (0.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from botocore<1.24.0,>=1.23.24->boto3->python-bioformats) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from botocore<1.24.0,>=1.23.24->boto3->python-bioformats) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.24->boto3->python-bioformats) (1.15.0)\n",
      "Requirement already satisfied: python-javabridge in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (4.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.1 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from python-javabridge) (1.20.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\shalev-ezra\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "#@markdown Run this cell to install the dependecies\n",
    "!pip install torch\n",
    "!pip install python-bioformats\n",
    "!pip install python-javabridge\n",
    "!pip install opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import scipy.stats as stats\n",
    "import tifffile\n",
    "from skimage import io\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import interpolate\n",
    "import pickle\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.signal import convolve2d\n",
    "import cv2\n",
    "from numpy.random import default_rng\n",
    "import numbers\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# matplotlib.use('TKAgg')\n",
    "\n",
    "def project_01(im):\n",
    "    # Squeeze the pixels value to be in range [0, 1]\n",
    "    if (im.sum() == 0):\n",
    "        return im\n",
    "    im = np.squeeze(im)\n",
    "    min_val = im.min()\n",
    "    max_val = im.max()\n",
    "    return (im - min_val) / (max_val - min_val)\n",
    "\n",
    "def project_percentile(im, percentile):\n",
    "    # Squeeze the pixels value to be in range [0, percentile_value]\n",
    "    if (im.sum() == 0):\n",
    "        return im\n",
    "    im = np.squeeze(im)\n",
    "    percentile_val = np.percentile(im, percentile)\n",
    "    comp_percentile_val = np.percentile(im, 2 * (100 - percentile))\n",
    "    return (im - comp_percentile_val) / percentile_val\n",
    "\n",
    "def read_cif(data_path, channels, image_size):\n",
    "    # Read cif file and pad each image and create tif for all specified channels\n",
    "    javabridge.start_vm(class_path=bioformats.JARS, max_heap_size='8G')\n",
    "    print('-I- Converting CIF to TIF')\n",
    "    # set default parameters\n",
    "    dirs = []\n",
    "    # call bioformats reader\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.endswith('.cif'):\n",
    "            np.random.seed(123)\n",
    "            # Make new dir for this file\n",
    "            dirs.append(os.path.join(data_path, filename[:-4]))\n",
    "            if (not os.path.isdir(os.path.join(data_path, filename[:-4]))):\n",
    "                os.mkdir(os.path.join(data_path, filename[:-4]))\n",
    "\n",
    "            single_channel_tensors = []\n",
    "            with bioformats.get_image_reader(key='tmp', path=os.path.join(data_path, filename)) as reader:\n",
    "                image_count = javabridge.call(reader.metadata, \"getImageCount\", \"()I\")\n",
    "                # channel_count = javabridge.call(reader.metadata, \"getChannelCount\", \"(I)I\", 0)\n",
    "\n",
    "                for j, ch in enumerate(channels):\n",
    "                    images = []\n",
    "                    # I use channel - 1 because channel 6 is named channel 5 in the cif file...\n",
    "                    # I iterate in jumps of two indices because each second image is a mask image and irrelevant\n",
    "                    for image in range(image_count)[::2]:\n",
    "                        images.append(reader.read(c=channels[j] - 1, series=image))\n",
    "\n",
    "                    cropped_images_this_channel = np.expand_dims(\n",
    "                        [__pad_and_project(image, image_size) for image in images], axis=3).astype(int)\n",
    "\n",
    "                    print('-I- Saving channel', ch)\n",
    "\n",
    "                    with tifffile.TiffWriter(os.path.join(data_path, '{}/{}_ch{}.tif'.format(filename[:-4], filename[:-4], ch))) as stack:\n",
    "                        for i in range(len(cropped_images_this_channel)):\n",
    "                            stack.write(cropped_images_this_channel[i, :, :, 0])\n",
    "\n",
    "    javabridge.kill_vm()\n",
    "    return dirs\n",
    "\n",
    "def __pad_and_project(image, image_size):\n",
    "    # make all images the same size: padding images with background noise of croppping images\n",
    "    if (not (image.sum() == 0)):\n",
    "        min_val = image.min()\n",
    "        max_val = image.max()\n",
    "        image = 255 * (image - min_val) / (max_val - min_val)\n",
    "\n",
    "    sample = image[int(image.shape[0] / 2) - 4:int(image.shape[0] / 2) + 4, :8]\n",
    "\n",
    "    std = np.std(sample)\n",
    "    mean = np.mean(sample)\n",
    "\n",
    "    if (image_size < image.shape[0]) & (image_size < image.shape[1]):\n",
    "        return image[:image_size, :image_size]\n",
    "    elif image_size < image.shape[0]:\n",
    "        tmp = np.random.normal(mean, std, [image_size, image_size])\n",
    "        tmp[:image_size, :image.shape[1]] = image[:image_size, :]\n",
    "        return tmp\n",
    "    elif image_size < image.shape[1]:\n",
    "        tmp = np.random.normal(mean, std, [image_size, image_size])\n",
    "        tmp[:image.shape[0], :image_size] = image[:, :image_size]\n",
    "        return tmp\n",
    "    else:\n",
    "        tmp = np.random.normal(mean, std, [image_size, image_size])\n",
    "        tmp[:image.shape[0], :image.shape[1]] = image\n",
    "        return tmp\n",
    "\n",
    "def LoadTIFF(file, path, size=None, cell_indices=None):\n",
    "    # Load a tiff stack\n",
    "    tiff = Image.open(os.path.join(path, file))\n",
    "    tiff.seek(0)\n",
    "    x0 = np.array(tiff)\n",
    "    if size == None:\n",
    "        size = tiff.n_frames\n",
    "    else:\n",
    "        size = np.min([size, tiff.n_frames])\n",
    "    data = []\n",
    "    if(cell_indices is None):\n",
    "        rng = default_rng()\n",
    "        cell_indices = rng.choice(tiff.n_frames, size=np.min([tiff.n_frames, size]), replace=False)\n",
    "    for i in range(size):\n",
    "        try:\n",
    "            tiff.seek(cell_indices[i])\n",
    "        except:\n",
    "            print('Specified stack length is too big - Finish reading the TIFF')\n",
    "            break\n",
    "        tmp = np.array(tiff)\n",
    "        if (tmp.size > 1):\n",
    "            data.append(tmp)\n",
    "        else:\n",
    "            data.append(np.zeros_like(x0))\n",
    "\n",
    "    return np.array(data), cell_indices\n",
    "\n",
    "def ShrinkImages(data, size, save_coord=False):\n",
    "    # Crop image according to size\n",
    "    left = int(np.argmax(data) % data.shape[1]) - int(size / 2)\n",
    "    down = int(np.argmax(data) / data.shape[1]) - int(size / 2)\n",
    "    right = left + size\n",
    "    up = down + size\n",
    "    if (left < 0):\n",
    "        left = 0\n",
    "        right = size\n",
    "    if (down < 0):\n",
    "        down = 0\n",
    "        up = size\n",
    "    if (right > data.shape[1]):\n",
    "        right = data.shape[1]\n",
    "        left = data.shape[1] - size\n",
    "    if (up > data.shape[0]):\n",
    "        up = data.shape[0]\n",
    "        down = data.shape[0] - size\n",
    "\n",
    "    if save_coord:\n",
    "        return data[down:up, left:right], np.array([down, left])\n",
    "    else:\n",
    "        return data[down:up, left:right]\n",
    "\n",
    "def ShrinkImages_ch4(data, size, ch2_shrink_coord, save_coord=False):\n",
    "    # Special crop for ch4 based on ch2 crop\n",
    "    down, left = ch2_shrink_coord.astype(int)\n",
    "    right = left + size\n",
    "    up = down + size\n",
    "    if save_coord:\n",
    "        return data[down:up, left:right], np.array([down, left])\n",
    "    else:\n",
    "        return data[down:up, left:right]\n",
    "\n",
    "def localize_emitters(orig_img, img, img_ch6, img_size, conf_threshold, detection_mode, verbose):\n",
    "    # Localize all the emitters in an image. The detection mode selects whether we fit beads\n",
    "    # to a singla Gaussian or loci to two Gaussians.\n",
    "    # Initialize parameters\n",
    "    pred_params_list = []\n",
    "    fit_quality_list = []\n",
    "    confidence_list = []\n",
    "\n",
    "    patch_size = 11\n",
    "    xy = np.zeros([2, int(patch_size ** 2)])\n",
    "    for i1 in range(patch_size):\n",
    "        for j1 in range(patch_size):\n",
    "            xy[:, int(i1 + patch_size * j1)] = [i1, j1]\n",
    "\n",
    "    xy_big = np.zeros([2, int(img_size ** 2)])\n",
    "    for i1 in range(img_size):\n",
    "        for j1 in range(img_size):\n",
    "            xy_big[:, int(i1 + img_size * j1)] = [i1, j1]\n",
    "\n",
    "    # Find potential peaks\n",
    "    min_dist = 5\n",
    "    potential_peaks_map = np.zeros_like(img)\n",
    "    num_of_peaks = 0\n",
    "    ind_list = []\n",
    "    potential_peaks = peak_local_max(img, num_peaks=5, threshold_rel=0.5)\n",
    "    for i in range(potential_peaks.shape[0]):\n",
    "        if(potential_peaks_map[potential_peaks[i, 0], potential_peaks[i, 1]] == 0):\n",
    "            num_of_peaks += 1\n",
    "            ind_list.append(i)\n",
    "            down = np.max([0, potential_peaks[i, 0]-min_dist])\n",
    "            up = np.min([img_size, potential_peaks[i, 0]+min_dist+1])\n",
    "            left = np.max([0, potential_peaks[i, 1]-min_dist])\n",
    "            right = np.min([img_size, potential_peaks[i, 1]+min_dist+1])\n",
    "            potential_peaks_map[down:up, left:right] = 1\n",
    "\n",
    "    potential_peaks = potential_peaks[ind_list]\n",
    "\n",
    "    # Filtering 0 loci or more than 2 loci\n",
    "    if (num_of_peaks < 1):\n",
    "        if (verbose):\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title('Did not detected loci')\n",
    "            plt.show()\n",
    "        return pred_params_list, fit_quality_list, confidence_list\n",
    "    elif(num_of_peaks > 2):\n",
    "        if (verbose):\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title('Too many loci detected - not analyzing more than 2')\n",
    "            plt.show()\n",
    "        return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "    for peak in range(num_of_peaks):\n",
    "        # Observe only small patch around peak\n",
    "        down = np.max([0, potential_peaks[peak, 0]-patch_size//2])\n",
    "        up = np.min([img_size-1, potential_peaks[peak, 0]+patch_size//2])\n",
    "        left = np.max([0, potential_peaks[peak, 1]-patch_size//2])\n",
    "        right = np.min([img_size-1, potential_peaks[peak, 1]+patch_size//2])\n",
    "\n",
    "        if(up+1-down < patch_size or right+1-left<patch_size):\n",
    "            if (verbose):\n",
    "                print(\"Locus is too close to image boundaries\")\n",
    "            if (peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        zobs = (img[down:up+1, left:right+1]).reshape(1, -1).squeeze()\n",
    "\n",
    "        # Position of maximal pixel in current patch\n",
    "        max_ind = np.argmax(zobs.reshape([patch_size, patch_size]))\n",
    "        try:\n",
    "            if(detection_mode == \"beads\"):\n",
    "                guess = [np.median(zobs), np.max(zobs), potential_peaks[peak, 1] - left, potential_peaks[peak, 0] - down, 2, 2]\n",
    "                bounds = ([0, 0, potential_peaks[peak, 1] - 0.5 - left, potential_peaks[peak, 0] - 0.5 - down, 0.5, 0.5],\n",
    "                          [np.inf, np.inf, potential_peaks[peak, 1] + 0.5 - left, potential_peaks[peak, 0] + 0.5 - down, 4, 4])\n",
    "                pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess, bounds=bounds)\n",
    "            else:\n",
    "                guess = [np.median(zobs), np.median(zobs), int(max_ind % (right-left)), int(max_ind / (up-down)), 3, 3,\n",
    "                         np.pi/2, np.max(zobs), potential_peaks[peak, 1] - left, potential_peaks[peak, 0] - down, 2, 2]\n",
    "                bounds = ([0, 0, 0, 0, 3, 3, 0, 0, potential_peaks[peak, 1] - 0.5 - left, potential_peaks[peak, 0] - 0.5 - down, 0.5, 0.5],\n",
    "                          [np.max(zobs), np.max(zobs), img_size - 1, img_size - 1, 4, 4, 2*np.pi, np.inf, potential_peaks[peak, 1] + 0.5 - left,\n",
    "                           potential_peaks[peak, 0] + 0.5 - down, 4, 4])\n",
    "                pred_params, uncert_cov = opt.curve_fit(gauss_on_gauss, xy, zobs, p0=guess, bounds=bounds)\n",
    "        except Exception as e:\n",
    "            if(verbose):\n",
    "                print(\"Could not fit to model\")\n",
    "            if(peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if(np.abs(pred_params[2] - bounds[0][2]) < 1e-3 or\n",
    "                np.abs(pred_params[2] - bounds[1][2]) < 1e-3 or\n",
    "                np.abs(pred_params[3] - bounds[0][3]) < 1e-3 or\n",
    "                np.abs(pred_params[3] - bounds[1][3]) < 1e-3):\n",
    "            if(peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if(detection_mode == \"beads\"):\n",
    "            loci_sig_x = pred_params[4]\n",
    "            loci_sig_y = pred_params[5]\n",
    "        else:\n",
    "            loci_sig_x = pred_params[10]\n",
    "            loci_sig_y = pred_params[11]\n",
    "            cell_sig_x = pred_params[4]\n",
    "            cell_sig_y = pred_params[5]\n",
    "\n",
    "        # Remove fit to bound values\n",
    "        if (loci_sig_x > 3.999 or loci_sig_y > 3.999):\n",
    "            if(verbose):\n",
    "                print(\"Predicted sigma is too big\")\n",
    "            if(peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if (detection_mode != \"beads\" or detection_mode != \"2D_beads\"):\n",
    "            # Do not allow the cell sigma be smaller than the loci sigma\n",
    "            # Cell sigma should be at least 2 times bigger than loci sigma\n",
    "            if (cell_sig_x < 2*loci_sig_x or cell_sig_y < 2*loci_sig_y):\n",
    "                if (verbose):\n",
    "                    title = 'Cell shape is too small compared of the locus shape'\n",
    "                    # Add zobs offset to localizations\n",
    "                    pred_params[2] += left\n",
    "                    pred_params[3] += down\n",
    "                    if (detection_mode != \"beads\"):\n",
    "                        pred_params[8] += left\n",
    "                        pred_params[9] += down\n",
    "                    plot_cell_fit(img_size, img, pred_params, title)\n",
    "                if (peak < num_of_peaks - 1):\n",
    "                    continue\n",
    "                return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "            # Filter cases where the fitted cell intensity is much higher than the loci\n",
    "            if (pred_params[1] / pred_params[7] > 1.5):\n",
    "                if (verbose):\n",
    "                    title = 'Cell intensity is too high compared to the loci intensity'\n",
    "                    # Add zobs offset to localizations\n",
    "                    pred_params[2] += left\n",
    "                    pred_params[3] += down\n",
    "                    if (detection_mode != \"beads\"):\n",
    "                        pred_params[8] += left\n",
    "                        pred_params[9] += down\n",
    "                    plot_cell_fit(img_size, img, pred_params, title)\n",
    "                if (peak < num_of_peaks - 1):\n",
    "                    continue\n",
    "                return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if (detection_mode == \"beads\"):\n",
    "            fit = gauss2d(xy, *pred_params)\n",
    "        else:\n",
    "            fit = gauss_on_gauss(xy, *pred_params)\n",
    "\n",
    "        # Calculate RMS\n",
    "        fit_quality = 1 - np.sqrt(np.mean((zobs / np.max(zobs) - fit / np.max(fit)) ** 2))\n",
    "\n",
    "        # Ensure fit quality is high enough\n",
    "        if (fit_quality > 0.9):\n",
    "            confidence = fit_quality * np.max(orig_img)\n",
    "            confidence = np.min([100, confidence])\n",
    "            confidence /= 2\n",
    "            if (confidence < conf_threshold):\n",
    "                if (peak < num_of_peaks - 1):\n",
    "                    continue\n",
    "                return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "            # Add zobs offset to localizations\n",
    "            pred_params[2] += left\n",
    "            pred_params[3] += down\n",
    "            if(detection_mode != \"beads\"):\n",
    "                pred_params[8] += left\n",
    "                pred_params[9] += down\n",
    "\n",
    "            # Add emitter to list\n",
    "            if(verbose):\n",
    "                plt.figure()\n",
    "                plt.suptitle('Accepted emitter')\n",
    "                plt.subplot(121)\n",
    "                plt.title('Image (ch2/4)')\n",
    "                plt.imshow(img)\n",
    "                plt.subplot(122)\n",
    "                if(detection_mode == \"beads\"):\n",
    "                    plt.imshow(gauss2d(xy_big, *pred_params).reshape([img_size, img_size]))\n",
    "                    plt.scatter(pred_params[2], pred_params[3], c='r', s=1)\n",
    "                else:\n",
    "                    plt.imshow(gauss_on_gauss(xy_big, *pred_params).reshape([img_size, img_size]))\n",
    "                    plt.scatter(pred_params[8], pred_params[9], c='r', s=1)\n",
    "                plt.title('Fit')\n",
    "                plt.show()\n",
    "\n",
    "            pred_params_list.append(pred_params)\n",
    "            fit_quality_list.append(fit_quality)\n",
    "            confidence_list.append(confidence)\n",
    "        else:\n",
    "            if (peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "    return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "def localize_emitters_bs(orig_img, img, img_size, conf_threshold, detection_mode, verbose):\n",
    "    # Same as localize_emitter function; however, here the results are divided to multiple batches\n",
    "    # This is done for statistical analysis of the results.\n",
    "    # Initialize parameters\n",
    "    pred_params_list = []\n",
    "    fit_quality_list = []\n",
    "    confidence_list = []\n",
    "\n",
    "    patch_size = 13\n",
    "    xy = np.zeros([2, int(patch_size ** 2)])\n",
    "    for i1 in range(patch_size):\n",
    "        for j1 in range(patch_size):\n",
    "            xy[:, int(i1 + patch_size * j1)] = [i1, j1]\n",
    "\n",
    "    xy_big = np.zeros([2, int(img_size ** 2)])\n",
    "    for i1 in range(img_size):\n",
    "        for j1 in range(img_size):\n",
    "            xy_big[:, int(i1 + img_size * j1)] = [i1, j1]\n",
    "\n",
    "    # Find potential peaks\n",
    "    min_dist = 5\n",
    "    potential_peaks_map = np.zeros_like(img)\n",
    "    num_of_peaks = 0\n",
    "    ind_list = []\n",
    "    potential_peaks = peak_local_max(img, num_peaks=5, threshold_rel=0.5)\n",
    "    for i in range(potential_peaks.shape[0]):\n",
    "        if(potential_peaks_map[potential_peaks[i, 0], potential_peaks[i, 1]] == 0):\n",
    "            num_of_peaks += 1\n",
    "            ind_list.append(i)\n",
    "            down = np.max([0, potential_peaks[i, 0]-min_dist])\n",
    "            up = np.min([img_size, potential_peaks[i, 0]+min_dist+1])\n",
    "            left = np.max([0, potential_peaks[i, 1]-min_dist])\n",
    "            right = np.min([img_size, potential_peaks[i, 1]+min_dist+1])\n",
    "            potential_peaks_map[down:up, left:right] = 1\n",
    "\n",
    "    potential_peaks = potential_peaks[ind_list]\n",
    "\n",
    "    # Filtering 0 loci or more than 2 loci\n",
    "    if (num_of_peaks < 1):\n",
    "        if (verbose):\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title('Did not detected loci')\n",
    "            plt.show()\n",
    "        return pred_params_list, fit_quality_list, confidence_list\n",
    "    elif(num_of_peaks > 2):\n",
    "        if (verbose):\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title('Too many loci detected - not analyzing more than 2')\n",
    "            plt.show()\n",
    "        return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "    for peak in range(num_of_peaks):\n",
    "        # Observe only small patch around peak\n",
    "        down = np.max([0, potential_peaks[peak, 0] - patch_size // 2])\n",
    "        up = np.min([img_size, potential_peaks[peak, 0] + patch_size // 2 + 1])\n",
    "        left = np.max([0, potential_peaks[peak, 1] - patch_size // 2])\n",
    "        right = np.min([img_size, potential_peaks[peak, 1] + patch_size // 2 + 1])\n",
    "\n",
    "        if(up-down < patch_size or right-left<patch_size):\n",
    "            if(down == 0):\n",
    "                up = patch_size\n",
    "            elif(up == img_size-1):\n",
    "                down = img_size - patch_size\n",
    "            if (left == 0):\n",
    "                right = patch_size\n",
    "            elif (right == img_size - 1):\n",
    "                left = img_size - patch_size\n",
    "\n",
    "        zobs = (img[down:up, left:right]).reshape(1, -1).squeeze()\n",
    "\n",
    "        # Position of maximal pixel in current patch\n",
    "        try:\n",
    "            if(detection_mode == \"beads\" or detection_mode == \"2D_beads\"):\n",
    "                guess = [np.median(zobs), np.max(zobs), potential_peaks[peak, 1] - left, potential_peaks[peak, 0] - down, 2, 2]\n",
    "                bounds = ([0, 0, potential_peaks[peak, 1] - 0.5 - left, potential_peaks[peak, 0] - 0.5 - down, 0.5, 0.5],\n",
    "                          [np.inf, np.inf, potential_peaks[peak, 1] + 0.5 - left, potential_peaks[peak, 0] + 0.5 - down, 4, 4])\n",
    "                pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess, bounds=bounds)\n",
    "            else:\n",
    "                guess = [np.median(zobs), np.median(zobs), potential_peaks[peak, 0] - left, potential_peaks[peak, 1] - down, 3, 3,\n",
    "                         np.pi/2, np.max(zobs), potential_peaks[peak, 1] - left, potential_peaks[peak, 0] - down, 0.75, 0.75]\n",
    "                bounds = ([0, 0, potential_peaks[peak, 1] - 5 - left, potential_peaks[peak, 0] - 5 - down, 3, 3, 0,\n",
    "                           2 * zobs.std(), potential_peaks[peak, 1] - 2 - left, potential_peaks[peak, 0] - 2 - down, 0.75, 0.75],\n",
    "                          [np.inf, np.inf, potential_peaks[peak, 1] + 4 - left, potential_peaks[peak, 0] + 4 - down, 4, 4, 2*np.pi,\n",
    "                           np.inf, potential_peaks[peak, 1] + 2 - left, potential_peaks[peak, 0] + 2 - down, 2.5, 2.5])\n",
    "                pred_params, uncert_cov = opt.curve_fit(gauss_on_gauss, xy, zobs, p0=guess, bounds=bounds, maxfev=15000)\n",
    "        except Exception as e:\n",
    "            if(verbose):\n",
    "                print(\"Could not fit to model\")\n",
    "            if(peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if(np.abs(pred_params[2] - bounds[0][2]) < 1e-3 or\n",
    "                np.abs(pred_params[2] - bounds[1][2]) < 1e-3 or\n",
    "                np.abs(pred_params[3] - bounds[0][3]) < 1e-3 or\n",
    "                np.abs(pred_params[3] - bounds[1][3]) < 1e-3):\n",
    "            if(peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if(detection_mode == \"beads\" or detection_mode == \"2D_beads\"):\n",
    "            loci_sig_x = pred_params[4]\n",
    "            loci_sig_y = pred_params[5]\n",
    "        else:\n",
    "            loci_sig_x = pred_params[10]\n",
    "            loci_sig_y = pred_params[11]\n",
    "            cell_sig_x = pred_params[4]\n",
    "            cell_sig_y = pred_params[5]\n",
    "\n",
    "        # Do not allow the cell sigma be smaller than the loci sigma\n",
    "        # Cell sigma should be at least 3 times bigger than loci sigma\n",
    "        if (detection_mode != \"beads\" and detection_mode != \"2D_beads\"):\n",
    "            if (cell_sig_x < 1.5*loci_sig_x or cell_sig_y < 1.5*loci_sig_y):\n",
    "                if (peak < num_of_peaks - 1):\n",
    "                    continue\n",
    "                return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "        if (detection_mode == \"beads\" or detection_mode == \"2D_beads\"):\n",
    "            fit = gauss2d(xy, *pred_params)\n",
    "        else:\n",
    "            fit = gauss_on_gauss(xy, *pred_params)\n",
    "\n",
    "        # Calculate RMS\n",
    "        fit_quality = 1 - np.sqrt(np.mean((zobs / np.max(zobs) - fit / np.max(fit)) ** 2))\n",
    "\n",
    "        # Ensure fit quality is high enough\n",
    "        if (fit_quality > 0.9):\n",
    "            confidence = fit_quality * np.max(orig_img)\n",
    "            confidence = np.min([100, confidence])\n",
    "            confidence /= 2\n",
    "            if (confidence < conf_threshold):\n",
    "                if (peak < num_of_peaks - 1):\n",
    "                    continue\n",
    "                return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "            # Add zobs offset to localizations\n",
    "            pred_params[2] += left\n",
    "            pred_params[3] += down\n",
    "            if(detection_mode != \"beads\" and detection_mode != \"2D_beads\"):\n",
    "                pred_params[8] += left\n",
    "                pred_params[9] += down\n",
    "\n",
    "            # Add emitter to list\n",
    "            pred_params_list.append(pred_params)\n",
    "            fit_quality_list.append(fit_quality)\n",
    "            confidence_list.append(confidence)\n",
    "        else:\n",
    "            if (peak < num_of_peaks - 1):\n",
    "                continue\n",
    "            return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "    return pred_params_list, fit_quality_list, confidence_list\n",
    "\n",
    "def localize_beads(orig_img, img, img_size, conf_threshold, verbose):\n",
    "    # Localizes beads in the given image\n",
    "    xy = np.zeros([2, int(img_size ** 2)])\n",
    "    for i1 in range(img_size):\n",
    "        for j1 in range(img_size):\n",
    "            xy[:, int(i1 + img_size * j1)] = [i1, j1]\n",
    "\n",
    "    # Fit the patch to a gaussian\n",
    "    zobs = (img).reshape(1, -1).squeeze()\n",
    "\n",
    "    max_ind = np.argmax(zobs.reshape([img_size, img_size]))\n",
    "    guess = [np.median(zobs), np.max(zobs), int(max_ind % img_size), int(max_ind / img_size), 2, 2]\n",
    "    bounds = ([0, 0, 0, 0, 0.5, 0.5], [np.inf, np.inf, img_size - 1, img_size - 1, 4, 4])\n",
    "    try:\n",
    "        pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess, bounds=bounds, maxfev=10000)\n",
    "    except:\n",
    "        return None, None, None\n",
    "\n",
    "    # Remove fit to bound values\n",
    "    if (pred_params[4] > 3.999 or pred_params[5] > 3.999):\n",
    "        return None, None, None\n",
    "\n",
    "    fit = gauss2d(xy, *pred_params)\n",
    "\n",
    "    # Calculate RMS\n",
    "    fit_quality = 1 - np.sqrt(np.mean((zobs / np.max(zobs) - fit / np.max(fit)) ** 2))\n",
    "\n",
    "    # Ensure fit quality is high enough\n",
    "    if (fit_quality > 0.95):\n",
    "        confidence = fit_quality * np.max(orig_img)\n",
    "        confidence = np.min([100, confidence])\n",
    "        confidence /= 2\n",
    "        if (confidence < conf_threshold):\n",
    "            if (verbose):\n",
    "                print(\"confidence level too low:\", confidence)\n",
    "            return None, None, None\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "    if (verbose):\n",
    "        plot_cell_fit(img_size, img, pred_params, 'Was not filtered', isBead=True)\n",
    "\n",
    "    return pred_params, fit_quality, confidence\n",
    "\n",
    "def plot_cell_fit(img_size, img, pred_params, title, cmap='gray', isBead=False):\n",
    "    # Plotting function for quality checks\n",
    "    xy = np.zeros([2, int(img_size ** 2)])\n",
    "    for i1 in range(img_size):\n",
    "        for j1 in range(img_size):\n",
    "            xy[:, int(i1 + img_size * j1)] = [i1, j1]\n",
    "\n",
    "    if(isBead):\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        plt.suptitle(title)\n",
    "        plt.subplot(121)\n",
    "        plt.title('Observed data')\n",
    "        im1 = plt.imshow(img, cmap=cmap)\n",
    "        fig.colorbar(im1, orientation='vertical')\n",
    "        plt.subplot(122)\n",
    "        plt.title('Fitted locus')\n",
    "        im2 = plt.imshow(gauss2d(xy, pred_params[0], pred_params[1], pred_params[2], pred_params[3], pred_params[4],\n",
    "                                 pred_params[5]).reshape([img_size, img_size]), cmap=cmap)\n",
    "        fig.colorbar(im2, orientation='vertical')\n",
    "    else:\n",
    "        plt.suptitle(title)\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(gauss2d_asym(xy, *pred_params[:7]).reshape([img_size, img_size]))\n",
    "        plt.title('cell fit')\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(gauss2d(xy, 0, pred_params[7], pred_params[8], pred_params[9],\n",
    "                           pred_params[10], pred_params[11]).reshape([img_size, img_size]))\n",
    "        plt.title('locus fit')\n",
    "        plt.subplot(223)\n",
    "        plt.imshow(img)\n",
    "        plt.scatter(pred_params[8], pred_params[9], c='r', s=1)\n",
    "        plt.title('original img')\n",
    "        plt.subplot(224)\n",
    "        plt.imshow(gauss_on_gauss(xy, *pred_params).reshape([img_size, img_size]))\n",
    "        plt.scatter(pred_params[8], pred_params[9], c='r', s=1)\n",
    "        plt.title('gauss on gauss fit')\n",
    "    plt.show()\n",
    "\n",
    "def loci_detection_bootstrap(path, filename, num_of_imgs, conf_threshold, SNR_thresh, shrink_size,\n",
    "                            xy_pos, calib, detection_mode, channel, shift_coord_list, analyzed_list, bootstrap_ind,\n",
    "                            verbose=False):\n",
    "    # A function that encapsulates all the emitter detection pipeline\n",
    "    # Initialize dictionary\n",
    "    ch_dict = {}\n",
    "\n",
    "    # Open TIFF files\n",
    "    tiff = Image.open(os.path.join(path, filename))\n",
    "\n",
    "    if(channel == 2):\n",
    "        cell_indices = np.arange((bootstrap_ind*num_of_imgs), (bootstrap_ind+1)*num_of_imgs)\n",
    "    else:\n",
    "        cell_indices = analyzed_list\n",
    "\n",
    "    # Start accumulating localizations\n",
    "    if(channel == 2):\n",
    "        shift_coord_list = []\n",
    "        analyzed_list = []\n",
    "    img_cnt = 0\n",
    "    curr_index = -1\n",
    "    pbar = tqdm(total=num_of_imgs)\n",
    "    while(img_cnt < num_of_imgs):\n",
    "        curr_index += 1\n",
    "        # Load current image\n",
    "        try:\n",
    "            tiff.seek(cell_indices[curr_index])\n",
    "        except:\n",
    "            print('Exception while reading tiff stack')\n",
    "            break\n",
    "        orig_img = np.array(tiff)\n",
    "        if (orig_img.size <= 1):\n",
    "            if(channel == 4):\n",
    "                ch_dict[curr_index] = [shift_coord_list[curr_index], [], 0, [], [], 0]\n",
    "                img_cnt += 1\n",
    "                pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        if(channel == 2):\n",
    "            orig_img, shift_coord = ShrinkImages(orig_img, shrink_size, save_coord=True)\n",
    "        else:\n",
    "            orig_img, shift_coord = ShrinkImages_ch4(orig_img, shrink_size, shift_coord_list[curr_index], save_coord=True)\n",
    "\n",
    "        img = project_percentile(orig_img, 90)\n",
    "\n",
    "        # Initialize output parameters\n",
    "        emitter_coordinates = []\n",
    "        emitter_sigmas = []\n",
    "        emitters_cnt = 0\n",
    "        # Filtering cells with bad SNR\n",
    "        curr_SNR = np.max(img) / np.mean(img)\n",
    "        if(type(SNR_thresh) is tuple):\n",
    "            if (curr_SNR < SNR_thresh[0] or curr_SNR > SNR_thresh[1]):\n",
    "                if (channel == 4):\n",
    "                    ch_dict[curr_index] = [shift_coord_list[curr_index], [], 0, [], [], 0]\n",
    "                    img_cnt += 1\n",
    "                    pbar.update(1)\n",
    "                continue\n",
    "        else:\n",
    "            if (curr_SNR < SNR_thresh):\n",
    "                if (channel == 4):\n",
    "                    ch_dict[curr_index] = [shift_coord_list[curr_index], [], 0, [], [], 0]\n",
    "                    img_cnt += 1\n",
    "                    pbar.update(1)\n",
    "                continue\n",
    "\n",
    "        img_size = img.shape[0]\n",
    "\n",
    "        xy = np.zeros([2, int(img_size ** 2)])\n",
    "        for i1 in range(img_size):\n",
    "            for j1 in range(img_size):\n",
    "                xy[:, int(i1 + img_size * j1)] = [i1, j1]\n",
    "        x, y = xy\n",
    "\n",
    "        max_ind = -1\n",
    "        similarity_max = 0\n",
    "\n",
    "        # Send data to localization algorithm\n",
    "        pred_params_list, fit_quality_list, confidence_list = localize_emitters_bs(orig_img, img, img_size,\n",
    "                                                                                   conf_threshold, detection_mode, verbose)\n",
    "\n",
    "        # Filter cell when localization algorithm failed\n",
    "        if (len(fit_quality_list) == 0):\n",
    "            if(verbose):\n",
    "                print(\"Localization algorithm failed\")\n",
    "            if (channel == 4):\n",
    "                ch_dict[curr_index] = [shift_coord_list[curr_index], emitter_coordinates, emitters_cnt, confidence_list, emitter_sigmas, curr_SNR]\n",
    "                img_cnt += 1\n",
    "                pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        if (detection_mode == \"beads\"):\n",
    "            for emitter in range(len(fit_quality_list)):\n",
    "                locus = gauss2d(xy, pred_params_list[emitter][0], pred_params_list[emitter][1],\n",
    "                                pred_params_list[emitter][2], pred_params_list[emitter][3],\n",
    "                                pred_params_list[emitter][4], pred_params_list[emitter][5]).reshape([img_size, img_size])\n",
    "                for i in range(xy_pos.shape[0]):\n",
    "                    exp_term = -((x - pred_params_list[emitter][2]) ** 2) / (2 * xy_pos[i, 0] ** 2) - \\\n",
    "                               ((y - pred_params_list[emitter][3]) ** 2) / (2 * xy_pos[i, 1] ** 2)\n",
    "                    curr_psf = (1 / (2 * np.pi * xy_pos[i, 0] * xy_pos[i, 1]) * np.exp(exp_term)).reshape([img_size, img_size])\n",
    "                    similarity_map = (locus - locus.mean()) * (curr_psf - curr_psf.mean()) / (locus.std() * curr_psf.std())\n",
    "                    similarity_val = np.sum(similarity_map)\n",
    "                    if (similarity_val > similarity_max):\n",
    "                        similarity_max = similarity_val\n",
    "                        max_ind = i\n",
    "\n",
    "                z = (calib[0, max_ind] + calib[1, max_ind]) / 2\n",
    "\n",
    "                emitter_coordinates.append([pred_params_list[emitter][2], pred_params_list[emitter][3], z])\n",
    "                emitters_cnt += 1\n",
    "                confidence_list.append(confidence_list[emitter])\n",
    "                emitter_sigmas.append([pred_params_list[emitter][4], pred_params_list[emitter][5]])\n",
    "                if(verbose):\n",
    "                    plot_cell_fit(img_size, img, pred_params_list[emitter], 'cell num = {}, z = {}'.format(cell_indices[curr_index], z), isBead=True)\n",
    "\n",
    "        elif(detection_mode == \"2D_beads\"):\n",
    "            for emitter in range(len(fit_quality_list)):\n",
    "                emitter_coordinates.append([pred_params_list[emitter][2], pred_params_list[emitter][3], 0])\n",
    "                emitters_cnt += 1\n",
    "                confidence_list.append(confidence_list[emitter])\n",
    "                emitter_sigmas.append([pred_params_list[emitter][4], pred_params_list[emitter][5]])\n",
    "\n",
    "        elif(detection_mode == \"2D\"):\n",
    "            for emitter in range(len(fit_quality_list)):\n",
    "                emitter_coordinates.append([pred_params_list[emitter][8], pred_params_list[emitter][9], 0])\n",
    "                emitters_cnt += 1\n",
    "                confidence_list.append(confidence_list[emitter])\n",
    "                emitter_sigmas.append([pred_params_list[emitter][10], pred_params_list[emitter][11]])\n",
    "\n",
    "        elif(detection_mode == \"3D\"):\n",
    "            for emitter in range(len(fit_quality_list)):\n",
    "                locus = gauss2d(xy, pred_params_list[emitter][0], pred_params_list[emitter][7],\n",
    "                                pred_params_list[emitter][8], pred_params_list[emitter][9],\n",
    "                                pred_params_list[emitter][10], pred_params_list[emitter][11]).reshape([img_size, img_size])\n",
    "                for i in range(xy_pos.shape[0]):\n",
    "                    exp_term = -((x - pred_params_list[emitter][8]) ** 2) / (2 * xy_pos[i, 0] ** 2) - \\\n",
    "                               ((y - pred_params_list[emitter][9]) ** 2) / (2 * xy_pos[i, 1] ** 2)\n",
    "                    curr_psf = (1 / (2 * np.pi * xy_pos[i, 0] * xy_pos[i, 1]) * np.exp(exp_term)).reshape([img_size, img_size])\n",
    "                    similarity_map = (locus - locus.mean()) * (curr_psf - curr_psf.mean()) / (locus.std() * curr_psf.std())\n",
    "                    similarity_val = np.sum(similarity_map)\n",
    "                    if (similarity_val > similarity_max):\n",
    "                        similarity_max = similarity_val\n",
    "                        max_ind = i\n",
    "\n",
    "                z = (calib[0, max_ind] + calib[1, max_ind]) / 2\n",
    "\n",
    "                emitter_coordinates.append([pred_params_list[emitter][8], pred_params_list[emitter][9], z])\n",
    "                emitters_cnt += 1\n",
    "                confidence_list.append(confidence_list[emitter])\n",
    "                emitter_sigmas.append([pred_params_list[emitter][10], pred_params_list[emitter][11]])\n",
    "\n",
    "                if(verbose):\n",
    "                    plot_cell_fit(img_size, img, pred_params_list[emitter], 'cell num {}, z = {}'.format(cell_indices[curr_index], z))\n",
    "\n",
    "        # Update dictionary and save important data\n",
    "        ch_dict[img_cnt] = [shift_coord, emitter_coordinates, emitters_cnt, confidence_list, emitter_sigmas, curr_SNR]\n",
    "        img_cnt += 1\n",
    "        if(channel == 2):\n",
    "            shift_coord_list.append(shift_coord)\n",
    "            analyzed_list.append(cell_indices[curr_index])\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Save dictionary\n",
    "    ch_file = open(os.path.join(path, \"ch{}_bs_{}_dict.pkl\".format(channel, bootstrap_ind)), \"wb\")\n",
    "    pickle.dump(ch_dict, ch_file)\n",
    "    ch_file.close()\n",
    "\n",
    "    return shift_coord_list, analyzed_list\n",
    "\n",
    "def find_loc_in_radius(xy_arr, curr, left, right, dist_thresh):\n",
    "    # Searches for data points in a radius around a given point\n",
    "    indices = []\n",
    "    for i in range(xy_arr.shape[0]):\n",
    "        if (left <= i) and (right >= i) and (np.abs(curr - xy_arr[i]) < dist_thresh):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def gauss2d(xy, offset, amp, x0, y0, sigmaX, sigmaY):\n",
    "    # Fit patch to gaussian\n",
    "    x, y = xy\n",
    "    return offset + (amp * np.exp(-((x - x0) ** 2) / (2 * sigmaX ** 2) - ((y - y0) ** 2) / (2 * sigmaY ** 2)))\n",
    "\n",
    "def gauss2d_asym(xy, offset, amp, x0, y0, sigmaX, sigmaY, theta):\n",
    "    # Fit patch to gaussian\n",
    "    x, y = xy\n",
    "    a = np.cos(theta) ** 2 / (2 * sigmaX ** 2) + np.sin(theta) ** 2 / (2 * sigmaY ** 2)\n",
    "    b = -np.sin(2 * theta) / (4 * sigmaX ** 2) + np.sin(2 * theta) / (4 * sigmaY ** 2)\n",
    "    c = np.sin(theta) ** 2 / (2 * sigmaX ** 2) + np.cos(theta) ** 2 / (2 * sigmaY ** 2)\n",
    "\n",
    "    return offset + (amp * np.exp(-(a*(x - x0) ** 2 + 2*b*(x - x0)*(y - y0) + c*(y - y0) ** 2)))\n",
    "\n",
    "def gauss_on_gauss(xy, os1, am1, x1, y1, sx1, sy1, theta, amp, x0, y0, sigmaX, sigmaY):\n",
    "    # Fit patch to gaussian\n",
    "    x, y = xy\n",
    "    a = np.cos(theta)**2 / (2 * sx1**2) + np.sin(theta)**2 / (2 * sy1**2)\n",
    "    b = -np.sin(2 * theta) / (4 * sx1**2) + np.sin(2 * theta) / (4 * sy1**2)\n",
    "    c = np.sin(theta)**2 / (2 * sx1**2) + np.cos(theta)**2 / (2 * sy1**2)\n",
    "\n",
    "    offset = os1 + (am1 * np.exp(-(a*(x - x1) ** 2 + 2*b*(x - x1)*(y - y1) + c*(y - y1) ** 2)))\n",
    "    return offset + (amp * np.exp(-((x - x0) ** 2) / (2 * sigmaX ** 2) - ((y - y0) ** 2) / (2 * sigmaY ** 2)))\n",
    "\n",
    "def generate_calibration(tiff_path, filename, bright_filename, SNR_th, L, z_max, step, channel, conf_threshold,\n",
    "                         random_cells, verbose=False):\n",
    "    # First Step: Load the TIFF file and localize assymetric PSFs, the output of this part is an array of SigmaX and\n",
    "    # SigmaY for each localization\n",
    "    tiff = Image.open(os.path.join(tiff_path, filename))\n",
    "    tiff_ch6 = Image.open(os.path.join(tiff_path, bright_filename))\n",
    "    xy_list = []\n",
    "    tiff.seek(0)\n",
    "    max_row, max_col = np.array(tiff).shape\n",
    "    fit_shape = np.min([max_col, max_row])\n",
    "\n",
    "    if (L == None):\n",
    "        L = tiff.n_frames\n",
    "    ind = np.random.randint(0, tiff.n_frames, np.min([tiff.n_frames, L]))\n",
    "    for i in tqdm(range(L)):\n",
    "        try:\n",
    "            if (random_cells):\n",
    "                tiff.seek(ind[i])\n",
    "                tiff_ch6.seek(ind[i])\n",
    "            else:\n",
    "                tiff.seek(i)\n",
    "                tiff_ch6.seek(i)\n",
    "        except:\n",
    "            print('Specified stack length is too big - Continuing calibration')\n",
    "            break\n",
    "        data = np.array(tiff)\n",
    "        # Filtering cells with bad SNR\n",
    "        curr_SNR = np.max(data) / np.mean(data)\n",
    "        if (type(SNR_th) is tuple):\n",
    "            if (curr_SNR < SNR_th[0] or curr_SNR > SNR_th[1]):\n",
    "                if (verbose):\n",
    "                    print(\"SNR is too low\")\n",
    "                continue\n",
    "        else:\n",
    "            if (curr_SNR < SNR_th):\n",
    "                if (verbose):\n",
    "                    print(\"SNR is too low\")\n",
    "                continue\n",
    "\n",
    "        pred_params, fit_quality, confidence = localize_emitters(data, project_percentile(data, 90),\n",
    "                                                                 np.array(tiff_ch6),\n",
    "                                                                 fit_shape, conf_threshold, detection_mode, verbose)\n",
    "\n",
    "        # Filter cell when the localization algorithm fail\n",
    "        if (len(fit_quality) == 0):\n",
    "            continue\n",
    "\n",
    "        for emitter in range(len(fit_quality)):\n",
    "            xy_list.append([pred_params[emitter][10], pred_params[emitter][11]])\n",
    "\n",
    "    xy_arr = np.array(xy_list)\n",
    "\n",
    "    print(\"{} cells out of {} were analyzed for the calibration\".format(xy_arr.shape[0], L))\n",
    "    # Second step: Fit a curve to the SigmaY-SigmaX graph.\n",
    "\n",
    "    upper_list = []\n",
    "    lower_list = []\n",
    "    for i in range(xy_arr.shape[0]):\n",
    "        if (xy_arr[i, 0] < xy_arr[i, 1]):\n",
    "            upper_list.append(i)\n",
    "        else:\n",
    "            lower_list.append(i)\n",
    "\n",
    "    xy_upper = xy_arr[upper_list, :]\n",
    "    xy_lower = xy_arr[lower_list, :]\n",
    "\n",
    "    dist_arr_u = np.sum(np.abs(xy_upper - np.array([1.0, 1.0])), axis=1)\n",
    "    dist_arr_l = np.sum(np.abs(xy_lower - np.array([1.0, 1.0])), axis=1)\n",
    "\n",
    "    sort_ind_u = np.argsort(dist_arr_u)[::-1]\n",
    "    sort_ind_l = np.argsort(dist_arr_l)\n",
    "\n",
    "    xy_sort = np.zeros([len(lower_list) + len(upper_list), 2])\n",
    "    xy_sort[:len(sort_ind_u), :] = xy_upper[sort_ind_u, :]\n",
    "    xy_sort[len(sort_ind_u):, :] = xy_lower[sort_ind_l, :]\n",
    "\n",
    "    # Build a list of the spline function, one for each dimension:\n",
    "    spl_x = interpolate.splrep(np.arange(xy_sort.shape[0]), xy_sort[:, 0], s=xy_sort.shape[0])\n",
    "    points_fitted_x = interpolate.splev(np.arange(xy_sort.shape[0]), spl_x)\n",
    "    spl_y = interpolate.splrep(np.arange(xy_sort.shape[0]), xy_sort[:, 1], s=xy_sort.shape[0])\n",
    "    points_fitted_y = interpolate.splev(np.arange(xy_sort.shape[0]), spl_y)\n",
    "\n",
    "    # Graph:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(np.linspace(0, xy_sort.shape[0], points_fitted_x.shape[0]), points_fitted_x, '-r',\n",
    "             label='fitted spline for sigmaX')\n",
    "    plt.plot(np.linspace(0, xy_sort.shape[0], points_fitted_y.shape[0]), points_fitted_y, '-b',\n",
    "             label='fitted spline for sigmaY')\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 0], s=0.5, c='k', label='Measured SigmaX')\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 1], s=0.5, c='c', label='Measured SigmaY')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Sample num')\n",
    "    plt.ylabel('Sig [um]')\n",
    "    plt.suptitle('Fit curve to rotated sigY-sigX graph')\n",
    "    plt.savefig(os.path.join(tiff_path, \"Fitted_curves_channel_{}.png\".format(channel)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Third part: draw the CDF of z positions along the polynomial and find the calibration function from SigmaX-SigmaY\n",
    "    # to z position\n",
    "    cnts_x = np.zeros_like(points_fitted_x)\n",
    "    cnts_y = np.zeros_like(points_fitted_y)\n",
    "    counted_x = np.zeros(xy_sort.shape[0])\n",
    "    counted_y = np.zeros(xy_sort.shape[0])\n",
    "    dist_thresh = 0.3\n",
    "    bins_x = np.linspace(0, xy_sort.shape[0], points_fitted_x.shape[0])\n",
    "    bins_y = np.linspace(0, xy_sort.shape[0], points_fitted_y.shape[0])\n",
    "    # Create the bounding boxes\n",
    "    for i in range(points_fitted_x.shape[0]):\n",
    "        curr_sig_x = points_fitted_x[i]\n",
    "        if (i == 0):\n",
    "            prev_x = bins_x[i]\n",
    "            next_x = bins_x[i + 1]\n",
    "        elif (i == points_fitted_x.shape[0] - 1):\n",
    "            prev_x = bins_x[i - 1]\n",
    "            next_x = bins_x[i]\n",
    "        else:\n",
    "            prev_x = bins_x[i - 1]\n",
    "            next_x = bins_x[i + 1]\n",
    "\n",
    "        indices_x = find_loc_in_radius(xy_sort[:, 0], curr_sig_x, prev_x, next_x, dist_thresh)\n",
    "        prev_count_x = np.sum(counted_x)\n",
    "        counted_x[indices_x] = 1\n",
    "        curr_count_x = np.sum(counted_x)\n",
    "        cnts_x[i] = curr_count_x - prev_count_x\n",
    "\n",
    "    for i in range(points_fitted_y.shape[0]):\n",
    "        curr_sig_y = points_fitted_y[i]\n",
    "        if (i == 0):\n",
    "            prev_y = bins_y[i]\n",
    "            next_y = bins_y[i + 1]\n",
    "        elif (i == points_fitted_y.shape[0] - 1):\n",
    "            prev_y = bins_y[i - 1]\n",
    "            next_y = bins_y[i]\n",
    "        else:\n",
    "            prev_y = bins_y[i - 1]\n",
    "            next_y = bins_y[i + 1]\n",
    "\n",
    "        indices_y = find_loc_in_radius(xy_sort[:, 1], curr_sig_y, prev_y, next_y, dist_thresh)\n",
    "        prev_count_y = np.sum(counted_y)\n",
    "        counted_y[indices_y] = 1\n",
    "        curr_count_y = np.sum(counted_y)\n",
    "        cnts_y[i] = curr_count_y - prev_count_y\n",
    "\n",
    "    cnts_x = np.cumsum(cnts_x)\n",
    "    cnts_y = np.cumsum(cnts_y)\n",
    "\n",
    "    # Assumptions:\n",
    "    # 1. the z range is [-2.2, 2.2] um\n",
    "    # 2. 95% of the beads are detectable in IFC\n",
    "    # 3. The beads z locations are distributed like a normal RV with mean = 0 and sigma = 1.375\n",
    "    # (erf(1.6)=97.5%, erf(-1.6)=2.5% so I divide 4.4/3.6=1.375)\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.optimize import Bounds\n",
    "\n",
    "    min_ind_X = np.argmin(points_fitted_x)\n",
    "    min_ind_Y = np.argmin(points_fitted_y)\n",
    "\n",
    "    upper_limit_X, lower_limit_X, expected_counts_X = get_expected_coutns(points_fitted_x, min_ind_X,\n",
    "                                                                                      z_max, step, xy_sort)\n",
    "    upper_limit_Y, lower_limit_Y, expected_counts_Y = get_expected_coutns(points_fitted_y, min_ind_Y,\n",
    "                                                                                      z_max, step, xy_sort)\n",
    "\n",
    "    # Overwrite old z_values and expected values\n",
    "    rand_norm = stats.norm(0, 1.375)\n",
    "    z_values_X = np.linspace(upper_limit_X, lower_limit_X, 100)\n",
    "    expected_counts_X = rand_norm.cdf(z_values_X)\n",
    "    expected_counts_X -= expected_counts_X[0]\n",
    "    z_values_Y = np.linspace(upper_limit_Y, lower_limit_Y, 100)\n",
    "    expected_counts_Y = rand_norm.cdf(z_values_Y)\n",
    "    expected_counts_Y -= expected_counts_Y[0]\n",
    "\n",
    "    x_pred_z = np.zeros_like(z_values_X)\n",
    "    y_pred_z = np.zeros_like(z_values_Y)\n",
    "\n",
    "    xy_pos = np.zeros([z_values_X.shape[0], 2])\n",
    "    total_measured_x = cnts_x[-1]\n",
    "    total_measured_y = cnts_y[-1]\n",
    "    for i in range(z_values_X.shape[0]):\n",
    "        for j in range(1, cnts_x.shape[0]):\n",
    "            if (expected_counts_X[i] * total_measured_x > cnts_x[j - 1] and expected_counts_X[i] * total_measured_x <= cnts_x[j]):\n",
    "                x_pred_z[i] = 0.5 * z_values_X[i - 1] + 0.5 * z_values_X[i]\n",
    "                xy_pos[i, 0] = points_fitted_x[j]\n",
    "                break\n",
    "        for j in range(1, cnts_y.shape[0]):\n",
    "            if (expected_counts_Y[i] * total_measured_y > cnts_y[j - 1] and expected_counts_Y[i] * total_measured_y <= cnts_y[j]):\n",
    "                y_pred_z[i] = 0.5 * z_values_Y[i - 1] + 0.5 * z_values_Y[i]\n",
    "                xy_pos[i, 1] = points_fitted_y[j]\n",
    "                break\n",
    "\n",
    "    i = 0\n",
    "    while (x_pred_z[i] == 0):\n",
    "        x_pred_z[i] = upper_limit_X\n",
    "        i += 1\n",
    "    for j in range(np.max([i, 1]), x_pred_z.shape[0]):\n",
    "        if (x_pred_z[j] == 0):\n",
    "            x_pred_z[j] = (x_pred_z[j - 1] - x_pred_z[j]) + x_pred_z[j]\n",
    "    i = 0\n",
    "    while (y_pred_z[i] == 0):\n",
    "        y_pred_z[i] = upper_limit_Y\n",
    "        i += 1\n",
    "    for j in range(np.max([i, 1]), y_pred_z.shape[0]):\n",
    "        if (y_pred_z[j] == 0):\n",
    "            y_pred_z[j] = (y_pred_z[j - 1] - y_pred_z[j]) + y_pred_z[j]\n",
    "\n",
    "    # Draw the bins of different z positions on top of sigmaX and sigmaY graphs\n",
    "    points_of_intrest_x, loc_x = find_points_of_interest(bins_x, min_ind_X)\n",
    "    points_of_intrest_y, loc_y = find_points_of_interest(bins_y, min_ind_Y)\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(211)\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 0], c='k')\n",
    "    plt.xticks(points_of_intrest_x, ['-2.2um', '0um', '2.2um'])\n",
    "    plt.stem(points_of_intrest_x, loc_x)\n",
    "    plt.xlabel('z value / number of sample')\n",
    "    plt.ylabel('SigmaX')\n",
    "    plt.subplot(212)\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 1], c='k')\n",
    "    plt.xticks(points_of_intrest_y, ['-2.2um', '0um', '2.2um'])\n",
    "    plt.stem(points_of_intrest_y, loc_y)\n",
    "    plt.xlabel('z value / number of sample')\n",
    "    plt.ylabel('SigmaY')\n",
    "    plt.savefig(os.path.join(tiff_path, \"Binning on top of observed data_{}.png\".format(channel)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print('-I- Saving calibration as TIFF for channel', channel)\n",
    "    calib = np.array([x_pred_z, y_pred_z])\n",
    "    return xy_pos, calib\n",
    "\n",
    "def find_min_point(xy_arr):\n",
    "    # Search for the focus point in the sigX-sigY graph\n",
    "    return np.percentile(xy_arr[:, 0], 10), np.percentile(xy_arr[:, 1], 20)\n",
    "\n",
    "def generate_calibration_by_beads_10_11_22(tiff_path, filename, SNR_th, L, z_max, step, channel,\n",
    "                                           conf_threshold, random_cells, verbose=False):\n",
    "    # First Step: Load the TIFF file and localize asymmetric PSFs, the output of this part is an array of SigmaX and\n",
    "    # SigmaY for each localization\n",
    "    tiff = Image.open(os.path.join(tiff_path, filename))\n",
    "    xy_list = []\n",
    "    tiff.seek(0)\n",
    "    max_row, max_col = np.array(tiff).shape\n",
    "    fit_shape = np.min([max_col, max_row])\n",
    "\n",
    "    if (L == None):\n",
    "        L = tiff.n_frames\n",
    "    ind = np.random.randint(0, tiff.n_frames, np.min([tiff.n_frames, L]))\n",
    "    for i in tqdm(range(L)):\n",
    "        try:\n",
    "            if (random_cells):\n",
    "                tiff.seek(ind[i])\n",
    "            else:\n",
    "                tiff.seek(i)\n",
    "        except:\n",
    "            print('Specified stack length is too big - Continuing calibration')\n",
    "            break\n",
    "        data = np.array(tiff)\n",
    "        # Filtering cells with bad SNR\n",
    "        curr_SNR = np.max(data) / np.mean(data)\n",
    "        if(type(SNR_th) is tuple):\n",
    "            if (curr_SNR < SNR_th[0] or curr_SNR > SNR_th[1]):\n",
    "                continue\n",
    "        else:\n",
    "            if (curr_SNR < SNR_th):\n",
    "                continue\n",
    "\n",
    "        pred_params, fit_quality, confidence = localize_beads(data, project_percentile(data, 90),\n",
    "                                                              fit_shape, conf_threshold, verbose)\n",
    "\n",
    "        # Filter cell when the localization algorithm fail\n",
    "        if (fit_quality == None):\n",
    "            continue\n",
    "\n",
    "        xy_list.append([pred_params[4], pred_params[5]])\n",
    "\n",
    "    xy_arr = np.array(xy_list)\n",
    "\n",
    "    print(\"{} cells out of {} were analyzed for the calibration\".format(xy_arr.shape[0], L))\n",
    "    # Second step: Fit a curve to the SigmaY-SigmaX graph.\n",
    "\n",
    "    upper_list = []\n",
    "    lower_list = []\n",
    "    min_pnt = find_min_point(xy_arr)\n",
    "    for i in range(xy_arr.shape[0]):\n",
    "        if (xy_arr[i, 0]*min_pnt[1] < xy_arr[i, 1]*min_pnt[0]):\n",
    "            upper_list.append(i)\n",
    "        else:\n",
    "            lower_list.append(i)\n",
    "\n",
    "    xy_upper = xy_arr[upper_list, :]\n",
    "    xy_lower = xy_arr[lower_list, :]\n",
    "\n",
    "    dist_arr_u = np.sum(np.abs(xy_upper - min_pnt), axis=1)\n",
    "    dist_arr_l = np.sum(np.abs(xy_lower - min_pnt), axis=1)\n",
    "\n",
    "    sort_ind_u = np.argsort(dist_arr_u)[::-1]\n",
    "    sort_ind_l = np.argsort(dist_arr_l)\n",
    "\n",
    "    xy_sort = np.zeros([len(lower_list) + len(upper_list), 2])\n",
    "    xy_sort[:len(sort_ind_u), :] = xy_upper[sort_ind_u, :]\n",
    "    xy_sort[len(sort_ind_u):, :] = xy_lower[sort_ind_l, :]\n",
    "\n",
    "    # Build a list of the spline function, one for each dimension:\n",
    "    spl_x = interpolate.splrep(np.arange(xy_sort.shape[0]), xy_sort[:, 0], s=5)\n",
    "    points_fitted_x = interpolate.splev(np.arange(xy_sort.shape[0]), spl_x)\n",
    "    spl_y = interpolate.splrep(np.arange(xy_sort.shape[0]), xy_sort[:, 1], s=5)\n",
    "    points_fitted_y = interpolate.splev(np.arange(xy_sort.shape[0]), spl_y)\n",
    "\n",
    "    # Graph:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(np.linspace(0, xy_sort.shape[0], points_fitted_x.shape[0]), points_fitted_x, '-r',\n",
    "             label='fitted spline for sigmaX')\n",
    "    plt.plot(np.linspace(0, xy_sort.shape[0], points_fitted_y.shape[0]), points_fitted_y, '-b',\n",
    "             label='fitted spline for sigmaY')\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 0], s=0.5, c='k', label='Measured SigmaX')\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 1], s=0.5, c='c', label='Measured SigmaY')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Sample num')\n",
    "    plt.ylabel('Sig [um]')\n",
    "    plt.suptitle('Fit curve to rotated sigY-sigX graph')\n",
    "    plt.savefig(os.path.join(tiff_path, \"Fitted_curves_channel_{}.png\".format(channel)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Third part: draw the CDF of z positions along the spline and find the calibration function from SigmaX-SigmaY\n",
    "    # to z position\n",
    "    cnts_x = np.zeros_like(points_fitted_x)\n",
    "    cnts_y = np.zeros_like(points_fitted_y)\n",
    "    counted_x = np.zeros(xy_sort.shape[0])\n",
    "    counted_y = np.zeros(xy_sort.shape[0])\n",
    "    dist_thresh = 0.3\n",
    "    bins_x = np.linspace(0, xy_sort.shape[0], points_fitted_x.shape[0])\n",
    "    bins_y = np.linspace(0, xy_sort.shape[0], points_fitted_y.shape[0])\n",
    "    # Create the bounding boxes\n",
    "    for i in range(points_fitted_x.shape[0]):\n",
    "        curr_sig_x = points_fitted_x[i]\n",
    "        if (i == 0):\n",
    "            prev_x = bins_x[i]\n",
    "            next_x = bins_x[i + 1]\n",
    "        elif (i == points_fitted_x.shape[0] - 1):\n",
    "            prev_x = bins_x[i - 1]\n",
    "            next_x = bins_x[i]\n",
    "        else:\n",
    "            prev_x = bins_x[i - 1]\n",
    "            next_x = bins_x[i + 1]\n",
    "\n",
    "        indices_x = find_loc_in_radius(xy_sort[:, 0], curr_sig_x, prev_x, next_x, dist_thresh)\n",
    "        prev_count_x = np.sum(counted_x)\n",
    "        counted_x[indices_x] = 1\n",
    "        curr_count_x = np.sum(counted_x)\n",
    "        cnts_x[i] = curr_count_x - prev_count_x\n",
    "\n",
    "    for i in range(points_fitted_y.shape[0]):\n",
    "        curr_sig_y = points_fitted_y[i]\n",
    "        if (i == 0):\n",
    "            prev_y = bins_y[i]\n",
    "            next_y = bins_y[i + 1]\n",
    "        elif (i == points_fitted_y.shape[0] - 1):\n",
    "            prev_y = bins_y[i - 1]\n",
    "            next_y = bins_y[i]\n",
    "        else:\n",
    "            prev_y = bins_y[i - 1]\n",
    "            next_y = bins_y[i + 1]\n",
    "\n",
    "        indices_y = find_loc_in_radius(xy_sort[:, 1], curr_sig_y, prev_y, next_y, dist_thresh)\n",
    "        prev_count_y = np.sum(counted_y)\n",
    "        counted_y[indices_y] = 1\n",
    "        curr_count_y = np.sum(counted_y)\n",
    "        cnts_y[i] = curr_count_y - prev_count_y\n",
    "\n",
    "    cnts_x = np.cumsum(cnts_x)\n",
    "    cnts_y = np.cumsum(cnts_y)\n",
    "\n",
    "    # Assumptions:\n",
    "    # 1. the z range is [-2.2, 2.2] um\n",
    "    # 2. 95% of the beads are detectable in IFC\n",
    "    # 3. The beads z locations are distributed like a normal RV with mean = 0 and sigma = 1.375\n",
    "    # (erf(1.6)=97.5%, erf(-1.6)=2.5% so I divide 4.4/3.2=1.375)\n",
    "    from scipy.optimize import minimize\n",
    "    from scipy.optimize import Bounds\n",
    "\n",
    "    min_ind_X = np.argmin(points_fitted_x)\n",
    "    min_ind_Y = np.argmin(points_fitted_y)\n",
    "\n",
    "    upper_limit_X, lower_limit_X, expected_counts_X = get_expected_coutns(points_fitted_x, min_ind_X,\n",
    "                                                                                      z_max, step, xy_sort)\n",
    "    upper_limit_Y, lower_limit_Y, expected_counts_Y = get_expected_coutns(points_fitted_y, min_ind_Y,\n",
    "                                                                                      z_max, step, xy_sort)\n",
    "\n",
    "    # Overwrite old z_values and expected values\n",
    "    rand_norm = stats.norm(0, 1.375)\n",
    "    z_values_X = np.linspace(upper_limit_X, lower_limit_X, 100)\n",
    "    expected_counts_X = rand_norm.cdf(z_values_X)\n",
    "    expected_counts_X -= expected_counts_X[0]\n",
    "    z_values_Y = np.linspace(upper_limit_Y, lower_limit_Y, 100)\n",
    "    expected_counts_Y = rand_norm.cdf(z_values_Y)\n",
    "    expected_counts_Y -= expected_counts_Y[0]\n",
    "\n",
    "    x_pred_z = np.zeros_like(z_values_X)\n",
    "    y_pred_z = np.zeros_like(z_values_Y)\n",
    "\n",
    "    xy_pos = np.zeros([z_values_X.shape[0], 2])\n",
    "    total_measured_x = cnts_x[-1]\n",
    "    total_measured_y = cnts_y[-1]\n",
    "    for i in range(z_values_X.shape[0]):\n",
    "        for j in range(1, cnts_x.shape[0]):\n",
    "            if (expected_counts_X[i] * total_measured_x > cnts_x[j - 1] and expected_counts_X[i] * total_measured_x <= cnts_x[j]):\n",
    "                x_pred_z[i] = 0.5 * z_values_X[i - 1] + 0.5 * z_values_X[i]\n",
    "                xy_pos[i, 0] = points_fitted_x[j]\n",
    "                break\n",
    "        for j in range(1, cnts_y.shape[0]):\n",
    "            if (expected_counts_Y[i] * total_measured_y > cnts_y[j - 1] and expected_counts_Y[i] * total_measured_y <= cnts_y[j]):\n",
    "                y_pred_z[i] = 0.5 * z_values_Y[i - 1] + 0.5 * z_values_Y[i]\n",
    "                xy_pos[i, 1] = points_fitted_y[j]\n",
    "                break\n",
    "\n",
    "    i = 0\n",
    "    while (x_pred_z[i] == 0):\n",
    "        x_pred_z[i] = upper_limit_X\n",
    "        i += 1\n",
    "    for j in range(np.max([i, 1]), x_pred_z.shape[0]):\n",
    "        if (x_pred_z[j] == 0):\n",
    "            x_pred_z[j] = (x_pred_z[j - 1] - x_pred_z[j]) + x_pred_z[j]\n",
    "    i = 0\n",
    "    while (y_pred_z[i] == 0):\n",
    "        y_pred_z[i] = upper_limit_Y\n",
    "        i += 1\n",
    "    for j in range(np.max([i, 1]), y_pred_z.shape[0]):\n",
    "        if (y_pred_z[j] == 0):\n",
    "            y_pred_z[j] = (y_pred_z[j - 1] - y_pred_z[j]) + y_pred_z[j]\n",
    "\n",
    "    # Draw the bins of different z positions on top of sigmaX and sigmaY graphs\n",
    "    points_of_intrest_x, loc_x = find_points_of_interest(bins_x, min_ind_X)\n",
    "    points_of_intrest_y, loc_y = find_points_of_interest(bins_y, min_ind_Y)\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(211)\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 0], c='k')\n",
    "    plt.xticks(points_of_intrest_x, ['{}um'.format(upper_limit_X), '0um', '{}um'.format(lower_limit_X)])\n",
    "    plt.stem(points_of_intrest_x, loc_x)\n",
    "    plt.xlabel('z value / number of sample')\n",
    "    plt.ylabel('SigmaX')\n",
    "    plt.subplot(212)\n",
    "    plt.scatter(np.arange(xy_sort.shape[0]), xy_sort[:, 1], c='k')\n",
    "    plt.xticks(points_of_intrest_y, ['{}um'.format(upper_limit_Y), '0um', '{}um'.format(lower_limit_Y)])\n",
    "    plt.stem(points_of_intrest_y, loc_y)\n",
    "    plt.xlabel('z value / number of sample')\n",
    "    plt.ylabel('SigmaY')\n",
    "    plt.savefig(os.path.join(tiff_path, \"Binning on top of observed data_{}.png\".format(channel)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print('-I- Saving calibration as TIFF for channel', channel)\n",
    "    calib = np.array([x_pred_z, y_pred_z])\n",
    "    return xy_pos, calib\n",
    "\n",
    "def get_expected_coutns(points_fitted, min_ind, z_max, step, xy_sort):\n",
    "    # Calculate the expected counts based on our Gaussian distribution assumption\n",
    "    mean = 0\n",
    "    std = 1.375\n",
    "    if(min_ind > points_fitted.shape[0]/2):\n",
    "        # Calculate expected counts for gaussian distribution with 95% of elements in [-2.2, 2.2] interval\n",
    "        z_values = np.linspace(0, 2.2, int((z_max + step) / step))\n",
    "\n",
    "        rand_norm = stats.norm(mean, std)\n",
    "        expected_counts = rand_norm.cdf(z_values) * 2 * min_ind\n",
    "        expected_counts -= expected_counts[0]\n",
    "\n",
    "        # Calculate the actual limit of the interval (Due to bad focus it might happen that not all beads are visible)\n",
    "        for i in range(expected_counts.shape[0]):\n",
    "            if(expected_counts[i] > (points_fitted.shape[0] - min_ind)):\n",
    "                lower_limit = z_values[i]\n",
    "                break\n",
    "            lower_limit = 2.2\n",
    "        upper_limit = -2.2\n",
    "    else:\n",
    "        # Calculate expected counts for gaussian distribution with 95% of elements in [-2.2, 2.2] interval\n",
    "        z_values = np.linspace(-2.2, 0, int((z_max + step) / step))\n",
    "\n",
    "        rand_norm = stats.norm(mean, std)\n",
    "        expected_counts = rand_norm.cdf(z_values) * 2 * (xy_sort.shape[0] - min_ind)\n",
    "\n",
    "        # Calculate the actual limit of the interval (Due to bad focus it might happen that not all beads are visible)\n",
    "        for i in range(expected_counts.shape[0]):\n",
    "            if (expected_counts[-1] - expected_counts[-(i + 1)] > min_ind):\n",
    "                upper_limit = z_values[-(i + 1)]\n",
    "                break\n",
    "            upper_limit = -2.2\n",
    "        lower_limit = 2.2\n",
    "\n",
    "    return upper_limit, lower_limit, expected_counts\n",
    "\n",
    "def find_points_of_interest(bins, min_ind):\n",
    "    # Find the points of interest in the calibration graph between sigX/Y and z\n",
    "    points_of_intrest = []\n",
    "    loc = []\n",
    "    points_of_intrest.append(bins[0])\n",
    "    loc.append(4)\n",
    "    points_of_intrest.append(bins[min_ind])\n",
    "    loc.append(4)\n",
    "    points_of_intrest.append(bins[-1])\n",
    "    loc.append(4)\n",
    "\n",
    "    return np.array(points_of_intrest), np.array(loc)\n",
    "\n",
    "def find_minimal_distance_assignment(list_ch2, list_ch4):\n",
    "    assignment_list_ch4 = []\n",
    "    for i in range(len(list_ch2)):\n",
    "        assignment_list_ch4.append(np.argmin(np.sum(np.abs((list_ch2[i] - np.array(list_ch4))), axis=1)))\n",
    "    return assignment_list_ch4\n",
    "\n",
    "def linear_func(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "def PlotCentroidCurveFit(dir_path, Cent_vs_dist_X, ind_curve_X, params_X, Cent_vs_dist_Y, ind_curve_Y, params_Y):\n",
    "    # Plot the fit of the distance correction function based on the position in the sensor\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle('Fitting the error in the distance as a function of the emitter position in the FOV')\n",
    "    plt.subplot(121)\n",
    "    plt.title('x vs dx')\n",
    "    plt.scatter(Cent_vs_dist_X[ind_curve_X, 0], Cent_vs_dist_X[ind_curve_X, 1], s=0.1)\n",
    "    plt.plot(Cent_vs_dist_X[ind_curve_X, 0], linear_func(Cent_vs_dist_X[ind_curve_X, 0], *params_X), 'r')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('dx')\n",
    "    plt.ylim([-0.5, 0.5])\n",
    "    plt.subplot(122)\n",
    "    plt.title('x vs dy')\n",
    "    plt.scatter(Cent_vs_dist_Y[ind_curve_Y, 0], Cent_vs_dist_Y[ind_curve_Y, 1], s=0.1)\n",
    "    plt.plot(Cent_vs_dist_Y[ind_curve_Y, 0], linear_func(Cent_vs_dist_Y[ind_curve_Y, 0], *params_Y), 'r')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('dy')\n",
    "    plt.ylim([-0.5, 0.5])\n",
    "    fig.savefig(os.path.join(dir_path, \"Location vs distance.png\"))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def Plot3DDistanceScatter(title, dir_path, dist_3d):\n",
    "    # Plot the 3D distance scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(dist_3d[:, 0], dist_3d[:, 1], dist_3d[:, 2], c=np.arange(dist_3d.shape[0]),\n",
    "               marker='x')\n",
    "    ax.set_xlabel('dist x[um]')\n",
    "    ax.set_ylabel('dist y[um]')\n",
    "    ax.set_zlabel('dist z[um]')\n",
    "    if (\"BeadsOnly\" in dir_path):\n",
    "        ax.set_xlim([-0.3, 0.3])\n",
    "        ax.set_ylim([-0.3, 0.3])\n",
    "        ax.set_zlim([-0.3, 0.3])\n",
    "    else:\n",
    "        ax.set_xlim([-1.0, 1.0])\n",
    "        ax.set_ylim([-1.0, 1.0])\n",
    "        ax.set_zlim([-1.0, 1.0])\n",
    "    plt.title(\"{} \\nAVGx = {:.5f}, AVGy = {:.5f}, AVGz = {:.5f} \\n STDx = {:.5f}, STDy = {:.5f}, STDz = {:.5f} \\n{}\".format(title,\n",
    "                                                                            np.mean(dist_3d[:, 0]),\n",
    "                                                                            np.mean(dist_3d[:, 1]),\n",
    "                                                                            np.mean(dist_3d[:, 2]),\n",
    "                                                                            np.std(dist_3d[:, 0]),\n",
    "                                                                            np.std(dist_3d[:, 1]),\n",
    "                                                                            np.std(dist_3d[:, 2]),\n",
    "                                                                            dir_path.split('\\\\')[-1]))\n",
    "    fig.savefig(os.path.join(dir_path, '{}.png'.format(title)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "def Plot3DDistanceHistogram(title, dir_path, dist_list):\n",
    "    # Plot a 3D distance line plot\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.plot(np.arange(0, 1.5 - 1 / 30, 1 / 30), np.histogram(dist_list, bins=np.arange(45) / 30)[0])\n",
    "    plt.title('{} \\nmedian={:.3f}, mean={:.3f}, STD={:.3f}, N={} \\n{}'.format(title,\n",
    "                                                                              np.median(dist_list),\n",
    "                                                                              np.mean(dist_list),\n",
    "                                                                              np.std(dist_list),\n",
    "                                                                              len(dist_list),\n",
    "                                                                              dir_path.split('\\\\')[-1]))\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))\n",
    "    plt.xlim([0, 1.5])\n",
    "    plt.savefig(os.path.join(dir_path, \"{}.png\".format(title)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def Plot3DLocalizationHistogram(title, dir_path, ch2_loc_list, ch4_loc_list):\n",
    "    # Plot the localization histogram\n",
    "    ch2_loc_arr = np.array(ch2_loc_list)\n",
    "    ch4_loc_arr = np.array(ch4_loc_list)\n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    plt.suptitle('Localization Histograms \\n{}'.format(dir_path.split('\\\\')[-1]))\n",
    "    plt.subplot(231)\n",
    "    plt.title('Ch2 - X')\n",
    "    plt.hist(ch2_loc_arr[:, 0], bins=np.arange(30) / 2)\n",
    "    plt.subplot(232)\n",
    "    plt.title('Ch2 - Y')\n",
    "    plt.hist(ch2_loc_arr[:, 1], bins=np.arange(30) / 2)\n",
    "    plt.subplot(233)\n",
    "    plt.title('Ch2 - Z')\n",
    "    plt.hist(ch2_loc_arr[:, 2], bins=np.arange(-2, 2, 0.2))\n",
    "    plt.subplot(234)\n",
    "    plt.title('Ch4 - X')\n",
    "    plt.hist(ch4_loc_arr[:, 0], bins=np.arange(30) / 2)\n",
    "    plt.subplot(235)\n",
    "    plt.title('Ch4 - Y')\n",
    "    plt.hist(ch4_loc_arr[:, 1], bins=np.arange(30) / 2)\n",
    "    plt.subplot(236)\n",
    "    plt.title('Ch4 - Z')\n",
    "    plt.hist(ch4_loc_arr[:, 2], bins=np.arange(-2, 2, 0.2))\n",
    "    plt.savefig(os.path.join(dir_path, \"{}.png\".format(title)))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def PlotCh01Plots(path, bootstrap_reps, timepoints_arr, sort_ind, mean_intensity_ch01, std_intensity_ch01,\n",
    "                  mean_rawmax_ch01, std_rawmax_ch01):\n",
    "    # Additional plots of ch1 data for quality checks\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if(bootstrap_reps > 1):\n",
    "        plt.errorbar(timepoints_arr[sort_ind], mean_intensity_ch01[sort_ind], std_intensity_ch01[sort_ind])\n",
    "    else:\n",
    "        plt.plot(timepoints_arr[sort_ind], mean_intensity_ch01[sort_ind])\n",
    "    plt.xlabel('time points [min]')\n",
    "    plt.ylabel('mean intensity ch01 over {} reps'.format(bootstrap_reps))\n",
    "    plt.title('Bootstrap of Intensity_Ch01 over {} reps'.format(bootstrap_reps))\n",
    "    plt.savefig(os.path.join(path, \"Intensity Ch01.png\"))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if(bootstrap_reps > 1):\n",
    "        plt.errorbar(timepoints_arr[sort_ind], mean_rawmax_ch01[sort_ind], std_rawmax_ch01[sort_ind])\n",
    "    else:\n",
    "        plt.plot(timepoints_arr[sort_ind], mean_rawmax_ch01[sort_ind])\n",
    "    plt.xlabel('time points [min]')\n",
    "    plt.ylabel('mean raw max ch01 over {} reps'.format(bootstrap_reps))\n",
    "    plt.title('Bootstrap of Raw Max Ch01 over {} reps'.format(bootstrap_reps))\n",
    "    plt.savefig(os.path.join(path, \"Raw Max Ch01.png\"))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMhul3Hc11_a"
   },
   "source": [
    "#Choose parameters\n",
    "**data_path** - indicate the pre-analyzed data location\n",
    "\n",
    "**SNR_thresh** - cells with lower Signal-to-Noise ration would be filtered\n",
    "\n",
    "**detection_mode** - measure 2D/ 3D distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "xLBr_HXy2DLE"
   },
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\shalev-ezra\\Documents\\YSE Doc_Con from F disk\\Ph.D\\ImageStream\\Alon Python Code\\Try\\Try_data' #@param {type:\"string\"}\n",
    "convert_cif_to_tif = True #@param {type:\"boolean\"}\n",
    "random_cells = True #@param {type:\"boolean\"}\n",
    "create_calibration_maps = True #@param {type:\"boolean\"}\n",
    "calibrate_by_beads = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Analyzing beads & cells\n",
    "\n",
    "analyze_beads_and_cells = True #@param {type:\"boolean\"}\n",
    "SNR_thresh_ch2 = 15 # for interval write: 15, 20 #@param {type:\"number\"}\n",
    "SNR_thresh_ch4 = 15 # for interval write: 15, 20 #@param {type:\"number\"}\n",
    "#@markdown The detection mode could be 2D / 3D / beads (analyzing only beads)\n",
    "detection_mode = \"3D\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Verbose = True will show more information during the calibration and loci detection steps. However, you should use it only during debug since it will make the run much slower.\n",
    "verbose = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3078eniz2cuI"
   },
   "source": [
    "##Convert cif to tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "X0IiHE2s2fK_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Converting CIF to TIF\n",
      "-I- Saving channel 2\n",
      "-I- Saving channel 4\n",
      "-I- Saving channel 6\n",
      "-I- Saving channel 2\n",
      "-I- Saving channel 4\n",
      "-I- Saving channel 6\n"
     ]
    }
   ],
   "source": [
    "#@markdown Run this cell to convert all cif files in the data_path to tiff files\n",
    "#@markdown The data will be aranged like this:\n",
    "\n",
    "#@markdown ----> data_path\n",
    "\n",
    "#@markdown -------------> cif_file_name_1\n",
    "\n",
    "#@markdown ----------------------> filename_ch2.tif\n",
    "\n",
    "#@markdown ----------------------> filename_ch4.tif\n",
    "\n",
    "#@markdown -------------> cif_file_name_2\n",
    "\n",
    "#@markdown ----------------------> filename_ch2.tif\n",
    "\n",
    "#@markdown ----------------------> filename_ch4.tif\n",
    "\n",
    "channels = (2,4,6)\n",
    "\n",
    "# ==== Do not edit these parameters === #\n",
    "shrink_size = 25\n",
    "conf_thresh = 2\n",
    "H, W = 64, 64  # for the final distance plot\n",
    "img_size = 64\n",
    "z_max = 2.2\n",
    "step = 0.01\n",
    "pixel_size = 0.33\n",
    "N_calibration_imgs = 1500\n",
    "bootstrap_reps = 1\n",
    "# ===================================== #\n",
    "if (convert_cif_to_tif):\n",
    "    import javabridge\n",
    "    import bioformats\n",
    "    dirs = read_cif(data_path=data_path, channels=channels, image_size=img_size)\n",
    "else:\n",
    "    dirs = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        if os.path.isdir(os.path.join(data_path, filename)):\n",
    "            dirs.append(os.path.join(data_path, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgQiqhmLAduS"
   },
   "source": [
    "##Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzeigU95AJbS",
    "outputId": "61eb9161-f3f3-42da-c2f2-d67951658d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Creating calibration maps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6d089ea0b94bc5816f6718ddbe8ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789 cells out of 1500 were analyzed for the calibration\n",
      "-I- Saving calibration as TIFF for channel 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc7e83347149b6b4600ad9a2bc43ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 cells out of 1500 were analyzed for the calibration\n",
      "-I- Saving calibration as TIFF for channel 4\n"
     ]
    }
   ],
   "source": [
    "#@markdown Run this cell to generate the calibration to all tiff files in the data_path\n",
    "print('-I- Creating calibration maps')\n",
    "if(detection_mode != \"2D\"):\n",
    "    for dir_path in dirs:\n",
    "        # ======= Calibration Step =======\n",
    "        if (calibrate_by_beads and \"BeadsOnly\" not in dir_path):\n",
    "            continue\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith(\"ch2.tif\"):\n",
    "                file_ch2 = filename\n",
    "            if filename.endswith(\"ch4.tif\"):\n",
    "                file_ch4 = filename\n",
    "\n",
    "        if (create_calibration_maps):\n",
    "            if (detection_mode == 'beads' or calibrate_by_beads):\n",
    "                xy_pos_ch2, calib_ch2 = generate_calibration_by_beads_10_11_22(dir_path, file_ch2, channel=2,\n",
    "                                                                               SNR_th=SNR_thresh_ch2, L=N_calibration_imgs,\n",
    "                                                                               z_max=z_max, step=step,\n",
    "                                                                               conf_threshold=conf_thresh,\n",
    "                                                                               random_cells=random_cells,\n",
    "                                                                               verbose=verbose)\n",
    "                xy_pos_ch4, calib_ch4 = generate_calibration_by_beads_10_11_22(dir_path, file_ch4, channel=4,\n",
    "                                                                               SNR_th=SNR_thresh_ch4, L=N_calibration_imgs,\n",
    "                                                                               z_max=z_max, step=step,\n",
    "                                                                               conf_threshold=conf_thresh,\n",
    "                                                                               random_cells=random_cells,\n",
    "                                                                               verbose=verbose)\n",
    "            else:\n",
    "                xy_pos_ch2, calib_ch2 = generate_calibration(dir_path, file_ch2, file_ch2, SNR_th=SNR_thresh_ch2,\n",
    "                                                             L=N_calibration_imgs, z_max=z_max, step=step, channel=2,\n",
    "                                                             conf_threshold=conf_thresh, random_cells=random_cells,\n",
    "                                                             verbose=False)\n",
    "                xy_pos_ch4, calib_ch4 = generate_calibration(dir_path, file_ch4, file_ch2, SNR_th=SNR_thresh_ch4,\n",
    "                                                             L=N_calibration_imgs, z_max=z_max, step=step, channel=2,\n",
    "                                                             conf_threshold=conf_thresh, random_cells=random_cells,\n",
    "                                                             verbose=False)\n",
    "\n",
    "            if(calibrate_by_beads and not detection_mode == \"beads\"):\n",
    "                np.save(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'xy_pos_ch2'), xy_pos_ch2)\n",
    "                np.save(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'xy_pos_ch4'), xy_pos_ch4)\n",
    "                np.save(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'calib_ch2'), calib_ch2)\n",
    "                np.save(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'calib_ch4'), calib_ch4)\n",
    "            else:\n",
    "                np.save(os.path.join(dir_path, 'xy_pos_ch2'), xy_pos_ch2)\n",
    "                np.save(os.path.join(dir_path, 'xy_pos_ch4'), xy_pos_ch4)\n",
    "                np.save(os.path.join(dir_path, 'calib_ch2'), calib_ch2)\n",
    "                np.save(os.path.join(dir_path, 'calib_ch4'), calib_ch4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xYPYHvbAiUZ"
   },
   "source": [
    "##Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457,
     "referenced_widgets": [
      "29252950efee4b189db2691b88e4fa77",
      "a783322fe6ce4e6f9dbb8f729f1e86d2",
      "f082df3f152d47fa847f897fe9e0a65f",
      "1e6fb28ff6264e57b50efee9ea60352e",
      "a15972d3cc134557b842390ada9b324a",
      "75f4650b267c4156aa05bd473e4cbc58",
      "8f99901165ca477a8cad334df4cf91dc",
      "3bfaa967eb95484d9ca6d97483e65615",
      "bce862fb02aa4e2ebd1812d574c028d5",
      "0033da2c7c504dd7a6943f665511eb3e",
      "b074ad2549b34e00bdae5ee05a986197",
      "d4dc1ea636c84c14ba0f29c37cf7cd55",
      "018a6e609c434f2da8d4e02656ee5eb9",
      "1b69a525e7cb414bad5e366f96b0ca58",
      "b68b2c87e63e4420a3ede4f8ea3e6f7b",
      "aafad5a322e74bb795ba3f8b7167fed2",
      "a5dff83ab97049558d275a0a46068068",
      "6408868f2c12498bbd15371dac681b67",
      "f33f7bacfb6c419aa9352c2f53b37b13",
      "5d6f045df9c94319874437d8078c2c49",
      "05991e14362f45d3b1776063711cdda8",
      "ddd777f8ec9d4424b43e0af34b574e0a",
      "f387ad15b7b24bfebf3aed19e2e56e5c",
      "5703f4885750484885c81d2b209e2da6",
      "0257a4ab7ca74b2c978e44767989f7d6",
      "fad632e5a10b4479a4713587dc1a041e",
      "0430de357e6f4ce1a6b9878452e62795",
      "1288314722b94f7daa91ec80a7b57558",
      "3aa94d2e2b2142cd868f21a26a4504af",
      "8da6360e5d454560bf00736c91336128",
      "8403a39e7f5746e8aebc2bcd5801316f",
      "451e75017c294263825416caad32132b",
      "e8e159fae2014e0dba24f7e436a442da",
      "75b6f4d4de9a469f82ae199ff44c6e45",
      "2f3d3fcab6794812a65a993d4945e47d",
      "4137b249d012453f83d087e57d984614",
      "e3b7f9b8d92b49cc834f7bd53f728cc4",
      "11b604aeabff47789f3c6c73a450bcf8",
      "ac3f05266a5448e0a4a32d737b84ac02",
      "d5b931a207fc417fb9701f9478a6bd09",
      "48270c85777445909bd6dcf7680f2ea8",
      "e12a52620f214a2a8c79884bffafe6a8",
      "401e81d56b0547f0908b099657ed05ea",
      "a988f99c4840428fbe9eb5e1cab0f516"
     ]
    },
    "id": "2WKetubUASt6",
    "outputId": "6fb42e9c-a110-4e70-b766-ae65546c176b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Starting data analysis\n",
      "====================================================================================================\n",
      "Working on  YS0087B2_Rep1_0min_Ind_8_ch2.tif\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722b37ee60424140bf6c1c88e84b5a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-27a9423b4ec6>:750: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  exp_term = -((x - pred_params_list[emitter][8]) ** 2) / (2 * xy_pos[i, 0] ** 2) - \\\n",
      "<ipython-input-1-27a9423b4ec6>:751: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ((y - pred_params_list[emitter][9]) ** 2) / (2 * xy_pos[i, 1] ** 2)\n",
      "<ipython-input-1-27a9423b4ec6>:752: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  curr_psf = (1 / (2 * np.pi * xy_pos[i, 0] * xy_pos[i, 1]) * np.exp(exp_term)).reshape([img_size, img_size])\n",
      "<ipython-input-1-27a9423b4ec6>:752: RuntimeWarning: invalid value encountered in multiply\n",
      "  curr_psf = (1 / (2 * np.pi * xy_pos[i, 0] * xy_pos[i, 1]) * np.exp(exp_term)).reshape([img_size, img_size])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while reading tiff stack\n",
      "====================================================================================================\n",
      "Working on  YS0087B2_Rep1_0min_Ind_8_ch4.tif\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cfcc40bd6c49d09f710fa85c606221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while reading tiff stack\n",
      "====================================================================================================\n",
      "Working on  YS0087B2_Rep1_0min_Ind_8_BeadsOnly_ch2.tif\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a0866f8685436b91ceea5ae53353fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-27a9423b4ec6>:750: RuntimeWarning: invalid value encountered in true_divide\n",
      "  exp_term = -((x - pred_params_list[emitter][8]) ** 2) / (2 * xy_pos[i, 0] ** 2) - \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while reading tiff stack\n",
      "====================================================================================================\n",
      "Working on  YS0087B2_Rep1_0min_Ind_8_BeadsOnly_ch4.tif\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a27f033d6945b3874c57a75c8f07fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while reading tiff stack\n",
      "-I- Spots localization completed\n"
     ]
    }
   ],
   "source": [
    "#@markdown Run this cell to perform loci/ beads localization\n",
    "Localize = True\n",
    "if Localize:\n",
    "    print('-I- Starting data analysis')\n",
    "    for dir_path in dirs:\n",
    "        if (not analyze_beads_and_cells and \"BeadsOnly\" in dir_path):\n",
    "            continue\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith(\"ch2.tif\"):\n",
    "                print('='*100)\n",
    "                print(\"Working on \", filename)\n",
    "                print('='*100)\n",
    "\n",
    "                # Load calibration\n",
    "                if(detection_mode == \"2D\"):\n",
    "                    calib_ch2 = None\n",
    "                    xy_pos_ch2 = None\n",
    "                else:\n",
    "                    if(calibrate_by_beads and \"BeadsOnly\" in dir_path):\n",
    "                        calib_ch2 = np.load(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'calib_ch2.npy'))\n",
    "                        xy_pos_ch2 = np.load(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'xy_pos_ch2.npy'))\n",
    "                    else:\n",
    "                        calib_ch2 = np.load(os.path.join(dir_path, 'calib_ch2.npy'))\n",
    "                        xy_pos_ch2 = np.load(os.path.join(dir_path, 'xy_pos_ch2.npy'))\n",
    "\n",
    "                tiff = Image.open(os.path.join(dir_path, filename))\n",
    "                total_num_imgs = tiff.n_frames\n",
    "                N_cell_imgs = total_num_imgs // bootstrap_reps\n",
    "\n",
    "                # Fix the case where we want to analyze beads in 2D\n",
    "                if(detection_mode == \"2D\" and \"BeadsOnly\" in dir_path):\n",
    "                    curr_detection_mode = \"2D_beads\"\n",
    "                else:\n",
    "                    curr_detection_mode = detection_mode\n",
    "\n",
    "                for bs_i in range(bootstrap_reps):\n",
    "                    shift_coord_list, analyzed_list = loci_detection_bootstrap(dir_path, filename, num_of_imgs=N_cell_imgs,\n",
    "                                                                               conf_threshold=conf_thresh,\n",
    "                                                                               SNR_thresh=SNR_thresh_ch2,\n",
    "                                                                               shrink_size=shrink_size, xy_pos=xy_pos_ch2,\n",
    "                                                                               calib=calib_ch2, detection_mode=curr_detection_mode,\n",
    "                                                                               channel=2, shift_coord_list=None,\n",
    "                                                                               analyzed_list=None,\n",
    "                                                                               bootstrap_ind=bs_i, verbose=verbose)\n",
    "                    np.save(os.path.join(dir_path, 'analyzed_list_{}'.format(bs_i)), analyzed_list)\n",
    "                    np.save(os.path.join(dir_path, 'shift_coord_{}'.format(bs_i)), shift_coord_list)\n",
    "\n",
    "            if filename.endswith(\"ch4.tif\"):\n",
    "                print('='*100)\n",
    "                print(\"Working on \", filename)\n",
    "                print('='*100)\n",
    "\n",
    "                # Load calibration\n",
    "                if(detection_mode == \"2D\"):\n",
    "                    xy_pos_ch4 = None\n",
    "                    calib_ch4 = None\n",
    "                else:\n",
    "                    if(calibrate_by_beads and \"BeadsOnly\" in dir_path):\n",
    "                        calib_ch4 = np.load(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'calib_ch4.npy'))\n",
    "                        xy_pos_ch4 = np.load(os.path.join(dir_path.replace(\"_BeadsOnly\", \"\"), 'xy_pos_ch4.npy'))\n",
    "                    else:\n",
    "                        xy_pos_ch4 = np.load(os.path.join(dir_path, 'xy_pos_ch4.npy'))\n",
    "                        calib_ch4 = np.load(os.path.join(dir_path, 'calib_ch4.npy'))\n",
    "\n",
    "                # Fix the case where we want to analyze beads in 2D\n",
    "                if(detection_mode == \"2D\" and \"BeadsOnly\" in dir_path):\n",
    "                    curr_detection_mode = \"2D_beads\"\n",
    "                else:\n",
    "                    curr_detection_mode = detection_mode\n",
    "\n",
    "                for bs_i in range(bootstrap_reps):\n",
    "                    analyzed_list = np.load(os.path.join(dir_path, 'analyzed_list_{}.npy'.format(bs_i)))\n",
    "                    shift_coord_list = np.load(os.path.join(dir_path, 'shift_coord_{}.npy'.format(bs_i)))\n",
    "                    _, _ = loci_detection_bootstrap(dir_path, filename, num_of_imgs=N_cell_imgs,\n",
    "                                                    conf_threshold=conf_thresh, SNR_thresh=SNR_thresh_ch4,\n",
    "                                                    shrink_size=shrink_size, xy_pos=xy_pos_ch4, calib=calib_ch4,\n",
    "                                                    detection_mode=curr_detection_mode, channel=4,\n",
    "                                                    shift_coord_list=shift_coord_list, analyzed_list=analyzed_list,\n",
    "                                                    bootstrap_ind=bs_i, verbose=verbose)\n",
    "\n",
    "print('-I- Spots localization completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W69STxdAlBF"
   },
   "source": [
    "##Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "Yrcgf-KDANCB",
    "outputId": "528c8c99-e7f2-4265-f776-1d27887869e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analayzed 213.00 out of 466.00 cells - 45.71 %\n",
      "-I- Generating fix curve based on position in FOV vs distance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "C:\\Users\\shalev-ezra\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analayzed 15517.00 out of 30505.00 cells - 50.87 %\n",
      "-I- Generating fix curve based on position in FOV vs distance\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'AxesSubplot' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d551eed9e3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt_dirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_timepoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Violin graph + median'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Distance distribution'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0mcurr_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'AxesSubplot' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@markdown Run this cell to show and save plots showing the run's results\n",
    "import csv\n",
    "list_of_median_lists = []\n",
    "list_of_timepoints = []\n",
    "list_of_intensity_ch01_lists = []\n",
    "list_of_rawmax_ch01_lists = []\n",
    "for dir_path in dirs:\n",
    "    if (not analyze_beads_and_cells and \"BeadsOnly\" in dir_path):\n",
    "        continue\n",
    "\n",
    "    median_list = []\n",
    "    if (bootstrap_reps == 1):\n",
    "        excel_dict = {}\n",
    "        excel_index = 0\n",
    "\n",
    "    intensity_ch01_list = []\n",
    "    rawmax_ch01_list = []\n",
    "    for bs_i in range(bootstrap_reps):\n",
    "        file_to_read = open(os.path.join(dir_path, \"ch2_bs_{}_dict.pkl\".format(bs_i)), \"rb\")\n",
    "        ch2_dict = pickle.load(file_to_read)\n",
    "        file_to_read = open(os.path.join(dir_path, \"ch4_bs_{}_dict.pkl\".format(bs_i)), \"rb\")\n",
    "        ch4_dict = pickle.load(file_to_read)\n",
    "\n",
    "        analyzed_list = np.load(os.path.join(dir_path, 'analyzed_list_{}.npy'.format(bs_i)))\n",
    "        ch2_loc_list = []\n",
    "        ch4_loc_list = []\n",
    "        dist_list = []\n",
    "        dist_3d_list = []\n",
    "        count_problematic_cells = 0\n",
    "        with open(os.path.join(data_path, dir_path.split('\\\\')[-1]) + '.txt', 'r') as txt_file:\n",
    "            lines = []\n",
    "            cnt = 0\n",
    "            for line in txt_file:\n",
    "                lines.append(line)\n",
    "                if (line.split('\\t')[0] == \"Object Number\"):\n",
    "                    ind_offset = cnt\n",
    "                cnt += 1\n",
    "            cols = lines[ind_offset].split('\\t')\n",
    "            ind_offset += 1\n",
    "            # Find the right columns\n",
    "            for col in range(len(cols)):\n",
    "                if (cols[col] == \"Raw Centroid X\"):\n",
    "                    CentColX = col\n",
    "                if (cols[col] == \"Intensity_MC_Ch01\"):\n",
    "                    I_Ch01_col = col\n",
    "                if (cols[col] == \"Raw Max Pixel_MC_Ch01\"):\n",
    "                    RawMax_Ch01_col = col\n",
    "\n",
    "            # Generate statistics regarding Centroid X and Y\n",
    "            cent_x_list = []\n",
    "            cent_y_list = []\n",
    "            for i in range(ind_offset, len(lines) - 2):\n",
    "                cent_x_list.append(float(lines[i].split('\\t')[CentColX]))\n",
    "                intensity_ch01_list.append(float(lines[i].split('\\t')[I_Ch01_col]))\n",
    "                rawmax_ch01_list.append(float(lines[i].split('\\t')[RawMax_Ch01_col]))\n",
    "\n",
    "            mean_cent_x = np.mean(cent_x_list)\n",
    "            mean_cent_y = np.mean(cent_y_list)\n",
    "            std_cent_x = np.std(cent_x_list)\n",
    "            std_cent_y = np.std(cent_y_list)\n",
    "\n",
    "            Cent_vs_dist_X = []\n",
    "            Cent_vs_dist_Y = []\n",
    "            for i in range(len(ch2_dict)):\n",
    "                # Don't use beads/ cells that are located farther than one STD from the mean location\n",
    "                if (np.abs(float(lines[analyzed_list[i] + ind_offset].split('\\t')[CentColX]) - mean_cent_x) > std_cent_x):\n",
    "                    # print(\"Localization is too far from the center of the sensor\")\n",
    "                    count_problematic_cells += 1\n",
    "                    continue\n",
    "                if (ch2_dict[i][2] > 0 and ch4_dict[i][2] > 0):\n",
    "                    if (ch2_dict[i][2] != ch4_dict[i][2]):\n",
    "                        # print(\"Found different number of loci in ch2 and ch4\")\n",
    "                        count_problematic_cells += 1\n",
    "                        continue\n",
    "                    # Assign emitter from ch2 to ch4\n",
    "                    if (ch2_dict[i][2] <= 1):\n",
    "                        ind_ch4 = [0]\n",
    "                    else:\n",
    "                        ind_ch4 = find_minimal_distance_assignment(ch2_dict[i][1], ch4_dict[i][1])\n",
    "                    for emitter in range(ch2_dict[i][2]):\n",
    "                        cur_emitter_ch2 = ch2_dict[i][1][emitter]\n",
    "                        cur_emitter_ch4 = ch4_dict[i][1][ind_ch4[emitter]]\n",
    "                        ch2_loc = pixel_size * (np.concatenate([ch2_dict[0][0], np.zeros(1)], axis=0) + cur_emitter_ch2)\n",
    "                        ch4_loc = pixel_size * (np.concatenate([ch4_dict[0][0], np.zeros(1)], axis=0) + cur_emitter_ch4)\n",
    "\n",
    "                        # Filter cells where the distance is bigger than ~ the nucleus size\n",
    "                        tot_dist = np.sqrt((ch2_loc[0] - ch4_loc[0]) ** 2 + (ch2_loc[1] - ch4_loc[1]) ** 2 + (ch2_loc[2] - ch4_loc[2]) ** 2)\n",
    "                        if (tot_dist < 1.5):\n",
    "                            ch2_loc_list.append(ch2_loc)\n",
    "                            ch4_loc_list.append(ch4_loc)\n",
    "                            dist_list.append(tot_dist)\n",
    "                            dist_3d_list.append([ch2_loc[0] - ch4_loc[0], ch2_loc[1] - ch4_loc[1], ch2_loc[2] - ch4_loc[2]])\n",
    "\n",
    "                            # Create points of centroid vs total distance\n",
    "                            Cent_vs_dist_X.append([lines[i + ind_offset].split('\\t')[CentColX], ch2_loc[0] - ch4_loc[0]])\n",
    "                            Cent_vs_dist_Y.append([lines[i + ind_offset].split('\\t')[CentColX], ch2_loc[1] - ch4_loc[1]])\n",
    "\n",
    "                            ch2_sigX = ch2_dict[i][4][emitter][0]\n",
    "                            ch2_sigY = ch2_dict[i][4][emitter][1]\n",
    "                            ch4_sigX = ch4_dict[i][4][emitter][0]\n",
    "                            ch4_sigY = ch4_dict[i][4][emitter][1]\n",
    "\n",
    "                            if (bootstrap_reps == 1):\n",
    "                                # Save localization and distance before correction\n",
    "                                excel_dict[excel_index] = [analyzed_list[i] + 1, ch2_loc[0], ch2_loc[1], ch2_loc[2],\n",
    "                                                           ch2_sigX, ch2_sigY,  ch2_dict[i][5], ch4_loc[0],\n",
    "                                                           ch4_loc[1], ch4_loc[2], ch4_sigX, ch4_sigY, ch4_dict[i][5],\n",
    "                                                           dist_3d_list[-1][0], dist_3d_list[-1][1], dist_3d_list[-1][2], 0, 0, 0]\n",
    "                                excel_index += 1\n",
    "                        else:\n",
    "                            # print('Loci distance bigger than 1.5um {}'.format(i))\n",
    "                            count_problematic_cells += 1\n",
    "                else:\n",
    "                    count_problematic_cells += 1\n",
    "\n",
    "        print('Analayzed {:.2f} out of {:.2f} cells - {:.2f} %'.format(len(ch2_dict) - count_problematic_cells,\n",
    "                                                                       len(ch2_dict),\n",
    "                                                                       100 * (len(ch2_dict) - count_problematic_cells) / len(ch2_dict)))\n",
    "        print('-I- Generating fix curve based on position in FOV vs distance')\n",
    "\n",
    "        Cent_vs_dist_X = np.array(Cent_vs_dist_X, dtype=float)\n",
    "        Cent_vs_dist_Y = np.array(Cent_vs_dist_Y, dtype=float)\n",
    "\n",
    "        ind_curve_X = np.argsort(Cent_vs_dist_X[:, 0])\n",
    "        ind_curve_Y = np.argsort(Cent_vs_dist_Y[:, 0])\n",
    "\n",
    "        guess = [1, 1]\n",
    "        bounds = ([-np.inf, -np.inf], [np.inf, np.inf])\n",
    "\n",
    "        params_X, _ = opt.curve_fit(linear_func, Cent_vs_dist_X[ind_curve_X, 0], Cent_vs_dist_X[ind_curve_X, 1], p0=guess, bounds=bounds)\n",
    "        params_Y, _ = opt.curve_fit(linear_func, Cent_vs_dist_Y[ind_curve_Y, 0], Cent_vs_dist_Y[ind_curve_Y, 1], p0=guess, bounds=bounds)\n",
    "\n",
    "        if(bootstrap_reps == 1):\n",
    "         # Plot curve fit\n",
    "            PlotCentroidCurveFit(dir_path, Cent_vs_dist_X, ind_curve_X, params_X, Cent_vs_dist_Y, ind_curve_Y, params_Y)\n",
    "\n",
    "        dist_3d = np.array(dist_3d_list)\n",
    "        mean_x_dist = np.mean(linear_func(Cent_vs_dist_X[:, 0], *params_X))\n",
    "        mean_y_dist = np.mean(linear_func(Cent_vs_dist_Y[:, 0], *params_Y))\n",
    "        dist_3d_fix = np.copy(dist_3d)\n",
    "        for loc in range(dist_3d_fix.shape[0]):\n",
    "            # Compensate on the additional error added because of emitter position\n",
    "            dist_3d_fix[loc, 0] = dist_3d[loc, 0] - linear_func(Cent_vs_dist_X[loc, 0], *params_X)\n",
    "            dist_3d_fix[loc, 1] = dist_3d[loc, 1] - linear_func(Cent_vs_dist_Y[loc, 0], *params_Y)\n",
    "            dist_3d_fix[loc, 2] = dist_3d[loc, 2] - np.mean(dist_3d[:, 2])\n",
    "        fixed_dist_list = np.zeros_like(np.array(dist_list))\n",
    "        for loc in range(len(dist_list)):\n",
    "            fixed_dist_list[loc] = np.sqrt(dist_3d_fix[loc, 0] ** 2 +\n",
    "                                           dist_3d_fix[loc, 1] ** 2 +\n",
    "                                           dist_3d_fix[loc, 2] ** 2)\n",
    "        # open the file in the write mode\n",
    "        if (bootstrap_reps == 1):\n",
    "            with open(os.path.join(dir_path, \"raw_data3D.csv\"), 'w', encoding='UTF8', newline='') as f:\n",
    "                # create the csv writer\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['frame', 'ch2_x [um]', 'ch2_y [um]', 'ch2_z [um]', 'ch2_sigX', 'ch2_sigY', 'SNR_ch2',\n",
    "                                 'ch4_x [um]', 'ch4_y [um]', 'ch4_z [um]', 'ch4_sigX', 'ch4_sigY', 'SNR_ch4',\n",
    "                                 'dist_x', 'dist_y', 'dist_z', 'dist_x_fix', 'dist_y_fix', 'dist_z_fix'])\n",
    "\n",
    "                for i in range(len(excel_dict)):\n",
    "                    excel_dict[i][-3] = dist_3d_fix[i, 0]\n",
    "                    excel_dict[i][-2] = dist_3d_fix[i, 1]\n",
    "                    excel_dict[i][-1] = dist_3d_fix[i, 2]\n",
    "                    # write a row to the csv file\n",
    "                    writer.writerow(excel_dict[i])\n",
    "\n",
    "            np.save(os.path.join(dir_path, 'dist_arr'), np.array(dist_list))\n",
    "\n",
    "            # =============================================================================================================\n",
    "            # Plot 3d distance scatter\n",
    "            Plot3DDistanceScatter('3D distances between ch2 and ch4 before fix', dir_path, dist_3d)\n",
    "            Plot3DDistanceScatter('3D distances between ch2 and ch4 after fix', dir_path, dist_3d_fix)\n",
    "\n",
    "            # =============================================================================================================\n",
    "            from matplotlib import ticker\n",
    "\n",
    "            # Plot 3d distance histogram\n",
    "            Plot3DDistanceHistogram('Histogram of 3D distances before fix', dir_path, dist_list)\n",
    "            Plot3DDistanceHistogram('Histogram of 3D distances after fix', dir_path, fixed_dist_list)\n",
    "\n",
    "            np.save(os.path.join(dir_path, 'fixed_dist_arr'), np.array(fixed_dist_list))\n",
    "            # =============================================================================================================\n",
    "            # Plot 3D localization histogram\n",
    "            Plot3DLocalizationHistogram('3D_localization_histograms before_fix', dir_path, ch2_loc_list, ch4_loc_list)\n",
    "\n",
    "        median_list.append(np.median(fixed_dist_list))\n",
    "\n",
    "    # Append all the tracked parameters list for each time point\n",
    "    if(\"BeadsOnly\" not in dir_path):\n",
    "        list_of_intensity_ch01_lists.append(np.array(intensity_ch01_list))\n",
    "        list_of_rawmax_ch01_lists.append(np.array(rawmax_ch01_list))\n",
    "        list_of_median_lists.append(median_list)\n",
    "        if('min' in dir_path.split('\\\\')[-1]):\n",
    "            minutes_ind = dir_path.split('\\\\')[-1].find('min')\n",
    "            start_ind = dir_path.split('\\\\')[-1][minutes_ind-5:minutes_ind].rfind('_')\n",
    "            list_of_timepoints.append(int(dir_path.split('\\\\')[-1][minutes_ind-5+start_ind+1:minutes_ind]))\n",
    "            meaningful_ind_flag = True\n",
    "        else:\n",
    "            list_of_timepoints.append(dir_path.split('\\\\')[-1])\n",
    "            meaningful_ind_flag = False\n",
    "\n",
    "# Take the mean and std of each list over different bootstrap reps\n",
    "if(meaningful_ind_flag):\n",
    "    sort_ind = np.argsort(list_of_timepoints)\n",
    "else:\n",
    "    sort_ind = np.arange(len(list_of_timepoints))\n",
    "\n",
    "median_arr = np.array(list_of_median_lists)\n",
    "timepoints_arr = np.array(list_of_timepoints)\n",
    "mean_intensity_ch01 = np.zeros(len(list_of_timepoints))\n",
    "std_intensity_ch01 = np.zeros(len(list_of_timepoints))\n",
    "mean_rawmax_ch01 = np.zeros(len(list_of_timepoints))\n",
    "std_rawmax_ch01 = np.zeros(len(list_of_timepoints))\n",
    "for i in range(len(list_of_timepoints)):\n",
    "    mean_intensity_ch01[i] = np.mean(list_of_intensity_ch01_lists[i])\n",
    "    std_intensity_ch01[i] = np.std(list_of_intensity_ch01_lists[i])\n",
    "    mean_rawmax_ch01[i] = np.mean(list_of_rawmax_ch01_lists[i])\n",
    "    std_rawmax_ch01[i] = np.std(list_of_rawmax_ch01_lists[i])\n",
    "\n",
    "# Channel 1 plots\n",
    "PlotCh01Plots(data_path, bootstrap_reps, timepoints_arr, sort_ind, mean_intensity_ch01,\n",
    "              std_intensity_ch01, mean_rawmax_ch01, std_rawmax_ch01)\n",
    "\n",
    "if (bootstrap_reps > 1):\n",
    "    # Bootstrap distance error bar plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.errorbar(timepoints_arr[sort_ind], np.mean(median_arr[sort_ind, :], axis=1),\n",
    "                 np.std(median_arr[sort_ind, :], axis=1))\n",
    "    plt.xlabel('time points [min]')\n",
    "    plt.ylabel('mean median over {} reps'.format(bootstrap_reps))\n",
    "    plt.title('Bootstrap estimation of error bars over {} reps'.format(bootstrap_reps))\n",
    "    plt.savefig(os.path.join(data_path, \"distance_error_bar_graph.png\"))\n",
    "    if (verbose):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "else:\n",
    "    # Count number of relevant dirs\n",
    "    cnt_dirs = 0\n",
    "    for dir_path in dirs:\n",
    "        if (\"BeadsOnly\" not in dir_path):\n",
    "            cnt_dirs += 1\n",
    "\n",
    "    dist_arr_for_plot = np.zeros(cnt_dirs)\n",
    "\n",
    "    fig, axes = plt.subplots(1, cnt_dirs, sharex=True, figsize=(len(list_of_timepoints), 6))\n",
    "    fig.suptitle('Violin graph + median')\n",
    "    axes[0].set_ylabel('Distance distribution')\n",
    "    ind = 0\n",
    "    curr_ind = -1\n",
    "    for dir_path in dirs:\n",
    "        if (\"BeadsOnly\" in dir_path):\n",
    "            continue\n",
    "        for filename in os.listdir(dir_path):\n",
    "            if filename.endswith(\"ch2.tif\"):\n",
    "                if(meaningful_ind_flag):\n",
    "                    for index, tp in enumerate(timepoints_arr[sort_ind]):\n",
    "                        if((\"_\" + str(tp) + \"min\") in filename):\n",
    "                            curr_ind = index\n",
    "                            break\n",
    "                else:\n",
    "                    curr_ind += 1\n",
    "\n",
    "                dist_list = np.load(os.path.join(dir_path, 'fixed_dist_arr.npy'))\n",
    "\n",
    "                axes[curr_ind].plot([0.75, 1.25], [np.median(dist_list), np.median(dist_list)])\n",
    "                dist_arr_for_plot[curr_ind] = np.mean(dist_list)\n",
    "\n",
    "                if (ind == 0):\n",
    "                    axes[curr_ind].spines[\"right\"].set_visible(False)\n",
    "                    axes[curr_ind].spines[\"top\"].set_visible(False)\n",
    "                else:\n",
    "                    axes[curr_ind].spines[\"right\"].set_visible(False)\n",
    "                    axes[curr_ind].spines[\"top\"].set_visible(False)\n",
    "                    axes[curr_ind].spines[\"left\"].set_visible(False)\n",
    "                    axes[curr_ind].get_yaxis().set_ticks([])\n",
    "\n",
    "                axes[curr_ind].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "                axes[curr_ind].set_xlabel(str(timepoints_arr[sort_ind[curr_ind]]) + '({})'.format(len(dist_list)))\n",
    "                axes[curr_ind].violinplot(dist_list)\n",
    "                axes[curr_ind].set_ylim([0, 0.8])\n",
    "        ind += 1\n",
    "\n",
    "    fig.text(0.5, 0, 'Time points (# analyzed cells)', ha='center')\n",
    "    fig.text(-0.15, 0.5, 'Distance [um]', va='center', rotation='vertical')\n",
    "    plt.savefig(os.path.join(data_path, \"violin_graph_3D.png\"))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0033da2c7c504dd7a6943f665511eb3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "018a6e609c434f2da8d4e02656ee5eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5dff83ab97049558d275a0a46068068",
      "placeholder": "",
      "style": "IPY_MODEL_6408868f2c12498bbd15371dac681b67",
      "value": "14%"
     }
    },
    "0257a4ab7ca74b2c978e44767989f7d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8da6360e5d454560bf00736c91336128",
      "max": 5873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8403a39e7f5746e8aebc2bcd5801316f",
      "value": 3374
     }
    },
    "0430de357e6f4ce1a6b9878452e62795": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05991e14362f45d3b1776063711cdda8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11b604aeabff47789f3c6c73a450bcf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1288314722b94f7daa91ec80a7b57558": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b69a525e7cb414bad5e366f96b0ca58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f33f7bacfb6c419aa9352c2f53b37b13",
      "max": 4081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d6f045df9c94319874437d8078c2c49",
      "value": 572
     }
    },
    "1e6fb28ff6264e57b50efee9ea60352e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0033da2c7c504dd7a6943f665511eb3e",
      "placeholder": "",
      "style": "IPY_MODEL_b074ad2549b34e00bdae5ee05a986197",
      "value": "572/4081[00:30&lt;04:19,13.50it/s]"
     }
    },
    "29252950efee4b189db2691b88e4fa77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a783322fe6ce4e6f9dbb8f729f1e86d2",
       "IPY_MODEL_f082df3f152d47fa847f897fe9e0a65f",
       "IPY_MODEL_1e6fb28ff6264e57b50efee9ea60352e"
      ],
      "layout": "IPY_MODEL_a15972d3cc134557b842390ada9b324a"
     }
    },
    "2f3d3fcab6794812a65a993d4945e47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac3f05266a5448e0a4a32d737b84ac02",
      "placeholder": "",
      "style": "IPY_MODEL_d5b931a207fc417fb9701f9478a6bd09",
      "value": "57%"
     }
    },
    "3aa94d2e2b2142cd868f21a26a4504af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bfaa967eb95484d9ca6d97483e65615": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "401e81d56b0547f0908b099657ed05ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4137b249d012453f83d087e57d984614": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48270c85777445909bd6dcf7680f2ea8",
      "max": 5873,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e12a52620f214a2a8c79884bffafe6a8",
      "value": 3374
     }
    },
    "451e75017c294263825416caad32132b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48270c85777445909bd6dcf7680f2ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5703f4885750484885c81d2b209e2da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1288314722b94f7daa91ec80a7b57558",
      "placeholder": "",
      "style": "IPY_MODEL_3aa94d2e2b2142cd868f21a26a4504af",
      "value": "57%"
     }
    },
    "5d6f045df9c94319874437d8078c2c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6408868f2c12498bbd15371dac681b67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75b6f4d4de9a469f82ae199ff44c6e45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f3d3fcab6794812a65a993d4945e47d",
       "IPY_MODEL_4137b249d012453f83d087e57d984614",
       "IPY_MODEL_e3b7f9b8d92b49cc834f7bd53f728cc4"
      ],
      "layout": "IPY_MODEL_11b604aeabff47789f3c6c73a450bcf8"
     }
    },
    "75f4650b267c4156aa05bd473e4cbc58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8403a39e7f5746e8aebc2bcd5801316f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8da6360e5d454560bf00736c91336128": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f99901165ca477a8cad334df4cf91dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a15972d3cc134557b842390ada9b324a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5dff83ab97049558d275a0a46068068": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a783322fe6ce4e6f9dbb8f729f1e86d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75f4650b267c4156aa05bd473e4cbc58",
      "placeholder": "",
      "style": "IPY_MODEL_8f99901165ca477a8cad334df4cf91dc",
      "value": "14%"
     }
    },
    "a988f99c4840428fbe9eb5e1cab0f516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aafad5a322e74bb795ba3f8b7167fed2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac3f05266a5448e0a4a32d737b84ac02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b074ad2549b34e00bdae5ee05a986197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b68b2c87e63e4420a3ede4f8ea3e6f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05991e14362f45d3b1776063711cdda8",
      "placeholder": "",
      "style": "IPY_MODEL_ddd777f8ec9d4424b43e0af34b574e0a",
      "value": "572/4081[00:21&lt;01:40,34.91it/s]"
     }
    },
    "bce862fb02aa4e2ebd1812d574c028d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4dc1ea636c84c14ba0f29c37cf7cd55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_018a6e609c434f2da8d4e02656ee5eb9",
       "IPY_MODEL_1b69a525e7cb414bad5e366f96b0ca58",
       "IPY_MODEL_b68b2c87e63e4420a3ede4f8ea3e6f7b"
      ],
      "layout": "IPY_MODEL_aafad5a322e74bb795ba3f8b7167fed2"
     }
    },
    "d5b931a207fc417fb9701f9478a6bd09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddd777f8ec9d4424b43e0af34b574e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e12a52620f214a2a8c79884bffafe6a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e3b7f9b8d92b49cc834f7bd53f728cc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_401e81d56b0547f0908b099657ed05ea",
      "placeholder": "",
      "style": "IPY_MODEL_a988f99c4840428fbe9eb5e1cab0f516",
      "value": "3374/5873[00:49&lt;00:35,70.27it/s]"
     }
    },
    "e8e159fae2014e0dba24f7e436a442da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f082df3f152d47fa847f897fe9e0a65f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bfaa967eb95484d9ca6d97483e65615",
      "max": 4081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bce862fb02aa4e2ebd1812d574c028d5",
      "value": 572
     }
    },
    "f33f7bacfb6c419aa9352c2f53b37b13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f387ad15b7b24bfebf3aed19e2e56e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5703f4885750484885c81d2b209e2da6",
       "IPY_MODEL_0257a4ab7ca74b2c978e44767989f7d6",
       "IPY_MODEL_fad632e5a10b4479a4713587dc1a041e"
      ],
      "layout": "IPY_MODEL_0430de357e6f4ce1a6b9878452e62795"
     }
    },
    "fad632e5a10b4479a4713587dc1a041e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_451e75017c294263825416caad32132b",
      "placeholder": "",
      "style": "IPY_MODEL_e8e159fae2014e0dba24f7e436a442da",
      "value": "3374/5873[01:12&lt;00:52,47.58it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
